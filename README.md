- [ä¸‰ã€ MinerUæ¥å£æ–‡æ¡£](#ä¸‰-mineruæ¥å£æ–‡æ¡£)
  - [1. æ¦‚è§ˆ](#1-æ¦‚è§ˆ-2)
  - [2. æ¥å£ 1: /file\_parse - å•æ–‡ä»¶è§£æä¿å­˜](#2-æ¥å£-1-file_parse---å•æ–‡ä»¶è§£æä¿å­˜)
    - [2.1. è¯·æ±‚](#21-è¯·æ±‚-1)
    - [2.2. å“åº”](#22-å“åº”-1)
    - [2.3. è°ƒç”¨ç¤ºä¾‹](#23-è°ƒç”¨ç¤ºä¾‹)
  - [3. æ¥å£ 2: /file\_parse\_json - å•æ–‡ä»¶è§£æè¿”å›JSON](#3-æ¥å£-2-file_parse_json---å•æ–‡ä»¶è§£æè¿”å›json)
    - [3.1. è¯·æ±‚](#31-è¯·æ±‚-1)
    - [3.2. å“åº”](#32-å“åº”-1)
    - [3.3. è°ƒç”¨ç¤ºä¾‹](#33-è°ƒç”¨ç¤ºä¾‹)
  - [4. æ¥å£ 3: /batch\_parse - æ‰¹é‡è§£ææœåŠ¡å™¨å†…æ–‡ä»¶](#4-æ¥å£-3-batch_parse---æ‰¹é‡è§£ææœåŠ¡å™¨å†…æ–‡ä»¶)
    - [4.1. è¯·æ±‚](#41-è¯·æ±‚)
    - [4.2. å“åº”](#42-å“åº”)
    - [4.3. è°ƒç”¨ç¤ºä¾‹](#43-è°ƒç”¨ç¤ºä¾‹)
  - [5. æ³¨æ„äº‹é¡¹](#5-æ³¨æ„äº‹é¡¹-1)
  - [è¿ç»´è®°å½•](#è¿ç»´è®°å½•-1)
- [å››ã€ å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææ¥å£](#å››-å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææ¥å£)
  - [1. æ¦‚è§ˆ](#1-æ¦‚è§ˆ-3)
    - [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
  - [2. æ ¸å¿ƒæ¥å£: /paper\_vis](#2-æ ¸å¿ƒæ¥å£-paper_vis)
    - [2.1. è¯·æ±‚](#21-è¯·æ±‚-2)
    - [2.2. å“åº”](#22-å“åº”-2)
  - [3. è¾…åŠ©æ¥å£](#3-è¾…åŠ©æ¥å£)
    - [3.1. GET /health](#31-get-health)
    - [3.2. GET /status](#32-get-status)
  - [4. è°ƒç”¨ç¤ºä¾‹](#4-è°ƒç”¨ç¤ºä¾‹)
    - [4.1. Python è¯·æ±‚](#41-python-è¯·æ±‚)
    - [4.2. cURL ç¤ºä¾‹](#42-curl-ç¤ºä¾‹)
    - [4.3. JavaScript (Fetch API) ç¤ºä¾‹](#43-javascript-fetch-api-ç¤ºä¾‹)
  - [5. æ³¨æ„äº‹é¡¹](#5-æ³¨æ„äº‹é¡¹-2)
  - [è¿ç»´ç¬”è®°](#è¿ç»´ç¬”è®°-1)
- [äº”ã€ å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææœåŠ¡å¹³å°](#äº”-å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææœåŠ¡å¹³å°)
  - [1. æ¦‚è§ˆ](#1-æ¦‚è§ˆ-4)
  - [2. è®¿é—®åœ°å€](#2-è®¿é—®åœ°å€)
  - [3. æ³¨æ„äº‹é¡¹](#3-æ³¨æ„äº‹é¡¹)
  - [è¿ç»´è®°å½•](#è¿ç»´è®°å½•-2)


# ä¸‰ã€ MinerUæ¥å£æ–‡æ¡£

## 1. æ¦‚è§ˆ

- **API åç§°**: MinerU PDF æ–‡æ¡£è§£ææ¥å£
- **æ¥å£çŠ¶æ€**: `[ç¨³å®š]`
- **æ¥å£æè¿°**: æä¾›å¼ºå¤§çš„ PDF æ–‡æ¡£è§£æèƒ½åŠ›ï¼Œæ”¯æŒå°†æ–‡æ¡£è½¬æ¢ä¸º Markdownã€JSON ç­‰å¤šç§æ ¼å¼ï¼Œå¹¶èƒ½æå–è¡¨æ ¼ã€å…¬å¼å’Œå›¾ç‰‡ã€‚æ¥å£åˆ†ä¸ºä¸‰ç§æ¨¡å¼ï¼šä¸Šä¼ è§£æå¹¶ä¿å­˜åˆ°æœåŠ¡å™¨ã€ä¸Šä¼ è§£æç›´æ¥è¿”å› JSONã€å¤„ç†æœåŠ¡å™¨å†…éƒ¨å·²æœ‰çš„æ–‡ä»¶ã€‚

## 2. æ¥å£ 1: /file_parse - å•æ–‡ä»¶è§£æä¿å­˜

æ­¤æ¥å£ç”¨äºä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª PDF æ–‡ä»¶ï¼ŒæœåŠ¡å™¨è§£æåå°†ç»“æœä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚

### 2.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8003/file_parse`
- **è¯·æ±‚å‚æ•° **
  - è¯·æ±‚ä½“ä¸º `multipart/form-data`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å                | ç±»å‹    | æ˜¯å¦å¿…å¡« | é»˜è®¤å€¼                       | æè¿°                                                         |
| --------------------- | ------- | -------- | ---------------------------- | ------------------------------------------------------------ |
| `files`               | File    | æ˜¯       | -                            | ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ã€‚åœ¨ cURL æˆ– Postman ä¸­å¯ä»¥é‡å¤æ­¤å­—æ®µä»¥ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ã€‚ |
| `output_dir`          | string  | å¦       | `/data/mineru/parsed_output` | è§£æç»“æœåœ¨æœåŠ¡å™¨ä¸Šçš„ä¿å­˜ç›®å½•ã€‚                               |
| `lang_list`           | list    | å¦       | `["ch"]`                     | è¯­è¨€åˆ—è¡¨ï¼Œä¾‹å¦‚ `["ch", "en"]`ã€‚                              |
| `backend`             | string  | å¦       | `pipeline`                   | åç«¯è§£æå¼•æ“ç±»å‹ã€‚                                           |
| `parse_method`        | string  | å¦       | `auto`                       | è§£ææ–¹æ³•ã€‚                                                   |
| `formula_enable`      | boolean | å¦       | `true`                       | æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«ã€‚                                           |
| `table_enable`        | boolean | å¦       | `true`                       | æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«ã€‚                                           |
| `return_md`           | boolean | å¦       | `true`                       | æ˜¯å¦ç”Ÿæˆ `.md` æ–‡ä»¶ã€‚                                        |
| `return_middle_json`  | boolean | å¦       | `true`                       | æ˜¯å¦ç”Ÿæˆä¸­é—´è¿‡ç¨‹çš„ `.json` æ–‡ä»¶ã€‚                            |
| `return_content_list` | boolean | å¦       | `true`                       | æ˜¯å¦ç”Ÿæˆå†…å®¹åˆ—è¡¨çš„ `.json` æ–‡ä»¶ã€‚                            |
| `return_images`       | boolean | å¦       | `true`                       | æ˜¯å¦æå–å¹¶ä¿å­˜å›¾ç‰‡ã€‚                                         |
| `response_format_zip` | boolean | å¦       | `false`                      | æ˜¯å¦å°†æ‰€æœ‰è¾“å‡ºæ–‡ä»¶æ‰“åŒ…æˆ ZIP æ ¼å¼è¿”å›ã€‚                      |
| `start_page_id`       | integer | å¦       | `0`                          | è§£æçš„èµ·å§‹é¡µç ã€‚                                             |
| `end_page_id`         | integer | å¦       | `99999`                      | è§£æçš„ç»“æŸé¡µç ã€‚                                             |

### 2.2. å“åº”

- **æˆåŠŸå“åº”**

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
        "message": "Successfully parsed 1 file(s).",
        "output_dir": "/Users/xiaokong/task/2025/paper/backend/uploads/papers"
    }
    ```

- **å¤±è´¥å“åº”**

  - **HTTP çŠ¶æ€ç **: `400 Bad Request` / `500 Internal Server Error`
  - **å“åº”ä½“**: åŒ…å«é”™è¯¯ä¿¡æ¯çš„æ–‡æœ¬æˆ– JSONã€‚

### 2.3. è°ƒç”¨ç¤ºä¾‹

- **Python è¯·æ±‚**

  ```python
  # è¯·æ±‚å•ä¸ªæ–‡ä»¶ï¼Œä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
  # ï¼ˆè‹¥ä¸å†™output_diråˆ™é»˜è®¤ä¿å­˜åˆ°/data/mineru/parsed_output"ï¼‰
  import requests
  import time
  import os
  import sys
  
  # --- é…ç½® ---
  # æœåŠ¡åœ°å€
  SERVER_URL = "http://10.3.35.21:8003/file_parse"
  
  # 1. è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
  PDF_FILE_PATH = "æˆ‘ä»¬ä½äº/pdfsè·¯å¾„ä¸‹çš„ç”¨æˆ·ä¸Šä¼ ç”¨æ—¶é—´é‡å‘½åä¹‹åçš„æ–‡æ¡£"
  # 2. æŒ‡å®šä¿å­˜è·¯å¾„
  output_dir = "/Users/xiaokong/task/2025/paper/backend/uploads/papers"
  # --- é…ç½®ç»“æŸ ---
  print(f"--- å¯åŠ¨ /file_parse  ---")
  print(f"ä¸Šä¼ æ–‡ä»¶: {PDF_FILE_PATH}")
  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
  if not os.path.exists(PDF_FILE_PATH):
      print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¦ä¸Šä¼ çš„æ–‡ä»¶! è·¯å¾„: {PDF_FILE_PATH}")
      sys.exit(1)
  # å‡†å¤‡è¦æäº¤çš„è¡¨å•æ•°æ®
  form_data = {
      'backend': 'pipeline',
      'output_dir':output_dir
    # å…¶ä»–å‚æ•°å¯ä»¥åœ¨è¿™é‡Œé…ç½®
  }
  try:
      with open(PDF_FILE_PATH, 'rb') as f:
          files_to_upload = {
              'files': (os.path.basename(PDF_FILE_PATH), f, 'application/pdf')
          }
          print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...")
          # è®°å½•å¼€å§‹æ—¶é—´
          start_time = time.time()
          # å‘é€ POST è¯·æ±‚
          response = requests.post(SERVER_URL, files=files_to_upload, data=form_data)
          # è®°å½•ç»“æŸæ—¶é—´
          end_time = time.time()
          total_time = end_time - start_time
      # --- åˆ†æå“åº” ---
      if response.status_code == 200:
          print(f"çŠ¶æ€: æˆåŠŸ (200 OK)")
      else:
          print(f"çŠ¶æ€: å¤±è´¥ ({response.status_code})")
          print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
  
  except requests.exceptions.ConnectionError:
      print(f"é”™è¯¯: è¿æ¥è¢«æ‹’ç»ã€‚è¯·ç¡®ä¿ fast_api.py æ­£åœ¨ {SERVER_URL} è¿è¡Œã€‚")
  except Exception as e:
      print(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
  finally:
      print("-" * 30)
      print(f"åç«¯ '/file_parse' æµ‹è¯•ç»“æŸã€‚")
      if 'total_time' in locals():
          print(f"æ€»è¿è¡Œæ—¶é•¿: {total_time:.2f} ç§’")
      print("-" * 30)
  
  ```

- **cURL ç¤ºä¾‹**

  ```shell
  curl -X POST "http://10.3.35.21:8003/file_parse" \
    -F "files=@document1.pdf" \
    -F "output_dir=/custom/output/path" 
  ```

## 3. æ¥å£ 2: /file_parse_json - å•æ–‡ä»¶è§£æè¿”å›JSON

æ­¤æ¥å£ç”¨äºä¸Šä¼ å•ä¸ª PDF æ–‡ä»¶ï¼ŒæœåŠ¡å™¨è§£æåä¸å†™å…¥æ–‡ä»¶ï¼Œè€Œæ˜¯ç›´æ¥åœ¨å“åº”ä½“ä¸­è¿”å›åŒ…å« Markdown å…¨æ–‡ç­‰ä¿¡æ¯çš„ JSON å¯¹è±¡ã€‚

### 3.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8003/file_parse_json`
- **è¯·æ±‚å‚æ•°**
  - `file`: å•ä¸ªPDFæ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
  - å…¶ä»–å‚æ•°ï¼ˆå¦‚ `lang`, `backend` ç­‰ï¼‰ä¸ `/file_parse` æ¥å£ç±»ä¼¼ï¼Œä½†ä¸ºå•æ•°å½¢å¼ï¼ˆä¾‹å¦‚ `lang` è€Œä¸æ˜¯ `lang_list`ï¼‰ã€‚

| å‚æ•°å | ç±»å‹   | æ˜¯å¦å¿…å¡« | é»˜è®¤å€¼ | æè¿°                |
| ------ | ------ | -------- | ------ | ------------------- |
| `file` | File   | æ˜¯       | -      | å•ä¸ªPDFæ–‡ä»¶ã€‚       |
| `lang` | string | å¦       | `ch`   | è¯­è¨€ï¼Œä¾‹å¦‚ `"en"`ã€‚ |

### 3.2. å“åº” 

- **æˆåŠŸå“åº”**

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "filename": "document",
      "md_content": "# æ–‡æ¡£æ ‡é¢˜\n\nè¿™æ˜¯è§£æåçš„markdownå†…å®¹...",
      "middle_json": "{ç‰ˆé¢ä¿¡æ¯}",
      "content_list": "[å†…å®¹åˆ—è¡¨]",
      "figure_dict": {
          "figure_1": "iVBORw0KGgoAAAANSUhEUgA...ï¼ˆbase6ç¼–ç ï¼Œå¯ç›´æ¥è§£æä¸ºå›¾ç‰‡æ–‡ä»¶ï¼‰",
          "figure_2": "R0lGODlhAQABAIAAAAAAAP..."
      },
      "backend": "pipeline",
      "version": "2.5.4"
    }
    ```

### 3.3. è°ƒç”¨ç¤ºä¾‹ 

- **Python è¯·æ±‚**

  ```python
  import requests
  import time
  import os
  import sys
  import json
  
  '''{
    "filename": "document",
    "md_content": "# æ–‡æ¡£æ ‡é¢˜\n\nè¿™æ˜¯è§£æåçš„markdownå†…å®¹...",
    "middle_json": "{...}",
    "content_list": "[...]",
    "figure_dict": {"file_name","base64"},
    "backend": "pipeline",
    "version": "2.5.4"
  }'''
  # --- é…ç½® ---
  # æœåŠ¡åœ°å€
  SERVER_URL = "http://10.3.35.21:8003/file_parse_json"
  
  # 1. è¦ä¸Šä¼ çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„
  PDF_FILE_PATH = "/Users/xiaokong/task/2025/paper_vis/vis/arxiv/1ee8ca1c-3478-4c4f-9b77-379ff4d58982/2dbbabd2678ba74fcd9b08aadae975ae.pdf"
  
  # 2. å¯ä»¥æŠŠè¿”å›çš„JSONç»“æœä¿å­˜åœ¨æœ¬åœ°çš„è¿™ä¸ªæ–‡ä»¶é‡Œï¼Œåœ¨å®é™…ä½¿ç”¨ä¸­ä¹Ÿå¯ä»¥ç›´æ¥å½“ä½œå­—å…¸å˜é‡è¿”å›
  OUTPUT_JSON_PATH = "test_parsejson.json"
  # --- é…ç½®ç»“æŸ ---
  
  print(f"--- å¯åŠ¨ /file_parse_json æµ‹è¯• ---")
  print(f"ä¸Šä¼ æ–‡ä»¶: {PDF_FILE_PATH}")
  print(f"æœ¬åœ°JSONè¾“å‡ºè·¯å¾„: {OUTPUT_JSON_PATH}")
  
  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
  if not os.path.exists(PDF_FILE_PATH):
      print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¦ä¸Šä¼ çš„æ–‡ä»¶! è·¯å¾„: {PDF_FILE_PATH}")
      sys.exit(1)
  
  # å‡†å¤‡è¡¨å•æ•°æ® (ä½¿ç”¨æœåŠ¡å™¨é»˜è®¤å€¼)
  form_data = {
      'backend': 'pipeline'
    # è¿™é‡Œå¯ä»¥å†™å…¶ä»–å‚æ•°
  } 
  
  try:
      # æ‰“å¼€æ–‡ä»¶
      with open(PDF_FILE_PATH, 'rb') as f:
          # 'file' æ˜¯ @app.post å®šä¹‰çš„å­—æ®µå (æ³¨æ„ï¼Œä¸æ˜¯ 'files')
          files_to_upload = {
              'file': (os.path.basename(PDF_FILE_PATH), f, 'application/pdf')
          } 
          print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...")
          # è®°å½•å¼€å§‹æ—¶é—´
          start_time = time.time()
          # å‘é€ POST è¯·æ±‚
          response = requests.post(SERVER_URL, files=files_to_upload, data=form_data)
          # è®°å½•ç»“æŸæ—¶é—´
          end_time = time.time()
          total_time = end_time - start_time
      # --- åˆ†æå“åº” ---
      if response.status_code == 200:
          print(f"çŠ¶æ€: æˆåŠŸ (200 OK)")
          try:
              # 1. è·å–JSONç»“æœ
              result_json = response.json() # å¯ä»¥ç›´æ¥å–å‡ºè¿™ä¸ªå˜é‡ä½¿ç”¨
              print(f"æˆåŠŸä»æœåŠ¡å™¨è·å–JSONç»“æœã€‚")
              
              # 2. å°†ç»“æœå†™å…¥æœ¬åœ°æ–‡ä»¶
              with open(OUTPUT_JSON_PATH, 'w', encoding='utf-8') as f_out:
                  json.dump(result_json, f_out, ensure_ascii=False, indent=4)
              print(f"å·²å°†è¿”å›çš„JSONå†™å…¥åˆ°: {OUTPUT_JSON_PATH}")
              
          except Exception as e:
              print(f"è§£ææˆ–å†™å…¥JSONæ—¶å‡ºé”™: {e}")
      else:
          print(f"çŠ¶æ€: å¤±è´¥ ({response.status_code})")
          print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
  
  except requests.exceptions.ConnectionError:
      print(f"é”™è¯¯: è¿æ¥è¢«æ‹’ç»ã€‚è¯·ç¡®ä¿ fast_api.py æ­£åœ¨ {SERVER_URL} è¿è¡Œã€‚")
  except Exception as e:
      print(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
  
  finally:
      print("-" * 30)
      print(f"åç«¯ '/file_parse_json' æµ‹è¯•ç»“æŸã€‚")
      if 'total_time' in locals():
          print(f"æ€»è¿è¡Œæ—¶é•¿: {total_time:.2f} ç§’")
      print("-" * 30)
  
  ```

  **è§£æå‡ºå®é™…å›¾ç‰‡**ï¼š

  ```python
  import base64
  import os
  
  def decode_and_save_images(fig_dict):
      """
      éå† figure_dictï¼Œå°†å¹²å‡€çš„ Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®è§£ç ï¼Œå¹¶ç»Ÿä¸€ä¿å­˜ä¸º PNG æ–‡ä»¶ã€‚
  
      æ–‡ä»¶åå–è‡ªå­—å…¸çš„é”® (key)ï¼Œå¹¶æ·»åŠ  .png åç¼€ã€‚
      
      :param fig_dict: å­—å…¸ï¼Œé”®æ˜¯ä¸å¸¦åç¼€çš„æ–‡ä»¶åï¼Œå€¼æ˜¯çº¯ Base64 å­—ç¬¦ä¸²ã€‚
      """
      print("--- å¼€å§‹è§£ç å’Œä¿å­˜å›¾ç‰‡ ---")
  
      # éå†å­—å…¸
      for filename_base, base64_data in fig_dict.items():
          # 1. è®¾ç½®è¾“å‡ºæ–‡ä»¶åï¼Œç»Ÿä¸€ä½¿ç”¨ .png åç¼€
          output_filename = f"{filename_base}.png"
          
          try:
              # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼ŒBase64 æ•°æ®æ˜¯â€œå¹²å‡€â€çš„ï¼Œç›´æ¥ä½œä¸ºç¼–ç æ•°æ®
              img_encoded_data = base64_data
  
              # 2. è§£ç  Base64 æ•°æ®
              img_data = base64.b64decode(img_encoded_data)
  
              # 3. å†™å…¥æ–‡ä»¶
              with open(output_filename, "wb") as f:
                  f.write(img_data)
              
              print(f"æˆåŠŸä¿å­˜æ–‡ä»¶: {output_filename}")
  
          except Exception as e:
              # æ‰“å°é”™è¯¯ä¿¡æ¯ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
              print(f"é”™è¯¯ï¼šä¿å­˜æ–‡ä»¶ {output_filename} æ—¶å‘ç”Ÿé”™è¯¯ã€‚Base64 æ•°æ®å¯èƒ½æ— æ•ˆã€‚è¯¦ç»†é”™è¯¯: {e}")
  
  if __name__ == "__main__":
      decode_and_save_images(figure_dict)
  
  ```

  

- **cURL ç¤ºä¾‹**

  ```shell
  curl -X POST "http://10.3.35.21:8003/file_parse_json" \
    -F "file=@document.pdf" 
  ```

## 4. æ¥å£ 3: /batch_parse - æ‰¹é‡è§£ææœåŠ¡å™¨å†…æ–‡ä»¶

æ­¤æ¥å£ä¸ä¸Šä¼ æ–‡ä»¶ï¼Œè€Œæ˜¯å¤„ç†æœåŠ¡å™¨æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰ PDF æ–‡ä»¶ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡çš„ã€é¢„ç½®çš„è§£æä»»åŠ¡ã€‚

### 4.1. è¯·æ±‚ 

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8003/batch_parse`
- **è¯·æ±‚å‚æ•°**
  - è¯·æ±‚ä½“ä¸º `application/x-www-form-urlencoded`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å       | ç±»å‹   | æ˜¯å¦å¿…å¡« | é»˜è®¤å€¼                       | æè¿°                                             |
| ------------ | ------ | -------- | ---------------------------- | ------------------------------------------------ |
| `input_path` | string | æ˜¯       | -                            | **æœåŠ¡å™¨ä¸Š**çš„è¾“å…¥è·¯å¾„ï¼ˆå¯ä»¥æ˜¯å•ä¸ªæ–‡ä»¶æˆ–ç›®å½•ï¼‰ã€‚ |
| `output_dir` | string | å¦       | `/data/mineru/parsed_output` | è§£æç»“æœåœ¨æœåŠ¡å™¨ä¸Šçš„ä¿å­˜ç›®å½•ã€‚                   |

### 4.2. å“åº” 

- **æˆåŠŸå“åº”**

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "message": "Batch processing completed. Processed 2 files.",
      "output_dir": "/data/mineru/parsed_output",
      "results": [
        {
          "filename": "doc1.pdf",
          "status": "success",
          "output_files": ["doc1.md", "doc1_middle.json"]
        },
        {
          "filename": "doc2.pdf",
          "status": "failed",
          "error": "Processing error message"
        }
      ],
      "backend": "pipeline",
      "version": "2.5.4"
    }
    ```

### 4.3. è°ƒç”¨ç¤ºä¾‹

- **Python è¯·æ±‚**

  ```python
  import requests
  import time
  import os
  import sys
  import json
  
  # --- é…ç½® ---
  # æœåŠ¡åœ°å€
  SERVER_URL = "http://10.3.35.21:8003/batch_parse"
  
  # 1. ä½ è¦æœåŠ¡å™¨å¤„ç†çš„ã€æœåŠ¡å™¨æœ¬åœ°ã€‘çš„æ–‡ä»¶å¤¹è·¯å¾„
  INPUT_PATH_ON_SERVER = "/data/kongyb/batch/"
  # --- é…ç½®ç»“æŸ ---
  output_dir = "/data/kongyb/output/"
  print(f"--- å¯åŠ¨ /batch_parse æµ‹è¯• ---")
  print(f"è¯·æ±‚æœåŠ¡å™¨å¤„ç†è·¯å¾„: {INPUT_PATH_ON_SERVER}")
  
  # å‡†å¤‡è¦æäº¤çš„è¡¨å•æ•°æ®
  # è¿™ä¸ªæ¥å£ä¸ä¸Šä¼ æ–‡ä»¶ï¼Œåªå‘é€è¡¨å•å­—æ®µ
  form_data = {
      'input_path': INPUT_PATH_ON_SERVER,
      'backend': 'pipeline',
      'output_dir':output_dir
  }
  try:
      print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...")
      # è®°å½•å¼€å§‹æ—¶é—´
      start_time = time.time()
      # å‘é€ POST è¯·æ±‚
      response = requests.post(SERVER_URL, data=form_data)
      # è®°å½•ç»“æŸæ—¶é—´
      end_time = time.time()
      total_time = end_time - start_time
  
      # --- åˆ†æå“åº” ---
      if response.status_code == 200:
          print(f"çŠ¶æ€: æˆåŠŸ (200 OK)")
          print("æœåŠ¡å™¨è¿”å›çš„æ‰¹é‡å¤„ç†æŠ¥å‘Š:")
      else:
          print(f"çŠ¶æ€: å¤±è´¥ ({response.status_code})")
          print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
  except requests.exceptions.ConnectionError:
      print(f"é”™è¯¯: è¿æ¥è¢«æ‹’ç»ã€‚è¯·ç¡®ä¿ fast_api.py æ­£åœ¨ {SERVER_URL} è¿è¡Œã€‚")
  except Exception as e:
      print(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
  finally:
      print("-" * 30)
      print(f"åç«¯ '/batch_parse' æµ‹è¯•ç»“æŸã€‚")
      if 'total_time' in locals():
          print(f"æ€»è¿è¡Œæ—¶é•¿: {total_time:.2f} ç§’")
      print("-" * 30)
  ```

- **cURL ç¤ºä¾‹**

  ```shell
  curl -X POST "http://10.3.35.21:8003/batch_parse" \
    -F "input_path=/path/to/pdf/directory" \
    -F "output_dir=/custom/output/path" 
  ```

## 5. æ³¨æ„äº‹é¡¹

1. **ç¦æ­¢å¹¶å‘è¯·æ±‚**ï¼šæ­¤æœåŠ¡ä¸ºé‡åº¦ I/O å’Œ CPU/GPU å¯†é›†å‹ä»»åŠ¡ï¼Œå¹¶å‘è¯·æ±‚å¯èƒ½å¯¼è‡´å†…å­˜å ç”¨è¿‡é«˜ä¸”é€Ÿåº¦æ›´æ…¢ã€‚**<u>è¯·åŠ¡å¿…æŒ‰é¡ºåºã€å•ä¸ªåœ°å‘é€è¯·æ±‚ã€‚</u>**
2. **é•¿è¶…æ—¶è®¾ç½®**ï¼šPDF è§£ææ˜¯è€—æ—¶æ“ä½œï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§æ–‡ä»¶ã€‚å®¢æˆ·ç«¯åœ¨è°ƒç”¨æ—¶ï¼Œ`timeout` å‚æ•°åº”è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå¤§çš„å€¼ï¼ˆä¾‹å¦‚ 120ç§’æˆ–æ›´é«˜ï¼‰ã€‚

## è¿ç»´è®°å½•

- **æ¥å£ç«¯å£**: `8003`

- **é…ç½®é¡¹åœ°å€**: `/etc/systemd/system/mineru-api.service`

- **ä»£ç ä½ç½®**: `/data/wangmeng/anaconda3/envs/vllm/lib/python3.11/site-packages/mineru/cli/fast_api.py`

- **æ¥å£æºä»£ç **:

  ```python
  import uuid
  import os
  import re
  import tempfile
  import asyncio
  import uvicorn
  import click
  import zipfile
  from pathlib import Path
  import glob
  from fastapi import FastAPI, UploadFile, File, Form
  from fastapi.middleware.gzip import GZipMiddleware
  from fastapi.responses import JSONResponse, FileResponse
  from starlette.background import BackgroundTask
  from typing import List, Optional
  from loguru import logger
  from base64 import b64encode
  
  from mineru.cli.common import aio_do_parse, aio_do_parse_simple, read_fn, pdf_suffixes, image_suffixes
  from mineru.utils.cli_parser import arg_parse
  from mineru.utils.guess_suffix_or_lang import guess_suffix_by_path
  from mineru.version import __version__
  
  app = FastAPI()
  app.add_middleware(GZipMiddleware, minimum_size=1000)
  
  
  def sanitize_filename(filename: str) -> str:
      """
      æ ¼å¼åŒ–å‹ç¼©æ–‡ä»¶çš„æ–‡ä»¶å
      ç§»é™¤è·¯å¾„éå†å­—ç¬¦, ä¿ç•™ Unicode å­—æ¯ã€æ•°å­—ã€._- 
      ç¦æ­¢éšè—æ–‡ä»¶
      """
      sanitized = re.sub(r'[/\\\.]{2,}|[/\\]', '', filename)
      sanitized = re.sub(r'[^\w.-]', '_', sanitized, flags=re.UNICODE)
      if sanitized.startswith('.'):
          sanitized = '_' + sanitized[1:]
      return sanitized or 'unnamed'
  
  def cleanup_file(file_path: str) -> None:
      """æ¸…ç†ä¸´æ—¶ zip æ–‡ä»¶"""
      try:
          if os.path.exists(file_path):
              os.remove(file_path)
      except Exception as e:
          logger.warning(f"fail clean file {file_path}: {e}")
  
  def encode_image(image_path: str) -> str:
      """Encode image using base64"""
      with open(image_path, "rb") as f:
          return b64encode(f.read()).decode()
  
  def get_infer_result(file_suffix_identifier: str, pdf_name: str, parse_dir: str) -> Optional[str]:
      """ä»ç»“æœæ–‡ä»¶ä¸­è¯»å–æ¨ç†ç»“æœ"""
      result_file_path = os.path.join(parse_dir, f"{pdf_name}{file_suffix_identifier}")
      if os.path.exists(result_file_path):
          with open(result_file_path, "r", encoding="utf-8") as fp:
              return fp.read()
      return None
  
  
  @app.post(path="/file_parse",)
  async def parse_pdf(
          files: List[UploadFile] = File(...),
          output_dir: Optional[str] = Form(None),
          lang_list: List[str] = Form(["ch"]),
          backend: str = Form("pipeline"),
          parse_method: str = Form("auto"),
          formula_enable: bool = Form(True),
          table_enable: bool = Form(True),
          server_url: Optional[str] = Form(None),
          return_md: bool = Form(True),
          return_middle_json: bool = Form(True),
          return_model_output: bool = Form(False),
          return_content_list: bool = Form(True),
          return_images: bool = Form(False),
          response_format_zip: bool = Form(False),
          start_page_id: int = Form(0),
          end_page_id: int = Form(99999),
  ):
  
      # è·å–å‘½ä»¤è¡Œé…ç½®å‚æ•°
      config = getattr(app.state, "config", {})
  
      try:
          # è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
          if output_dir is None:
              output_dir = "/data/mineru/parsed_output"
          
          # åˆ›å»ºå”¯ä¸€çš„è¾“å‡ºç›®å½•
          unique_dir = os.path.join(output_dir, str(uuid.uuid4()))
          os.makedirs(unique_dir, exist_ok=True)
  
          # å¤„ç†ä¸Šä¼ çš„PDFæ–‡ä»¶
          pdf_file_names = []
          pdf_bytes_list = []
  
          for file in files:
              content = await file.read()
              file_path = Path(file.filename)
  
              # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
              temp_path = Path(unique_dir) / file_path.name
              with open(temp_path, "wb") as f:
                  f.write(content)
  
              # å¦‚æœæ˜¯å›¾åƒæ–‡ä»¶æˆ–PDFï¼Œä½¿ç”¨read_fnå¤„ç†
              file_suffix = guess_suffix_by_path(temp_path)
              if file_suffix in pdf_suffixes + image_suffixes:
                  try:
                      pdf_bytes = read_fn(temp_path)
                      pdf_bytes_list.append(pdf_bytes)
                      pdf_file_names.append(file_path.stem)
                      os.remove(temp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                  except Exception as e:
                      return JSONResponse(
                          status_code=400,
                          content={"error": f"Failed to load file: {str(e)}"}
                      )
              else:
                  return JSONResponse(
                      status_code=400,
                      content={"error": f"Unsupported file type: {file_suffix}"}
                  )
  
  
          # è®¾ç½®è¯­è¨€åˆ—è¡¨ï¼Œç¡®ä¿ä¸æ–‡ä»¶æ•°é‡ä¸€è‡´
          actual_lang_list = lang_list
          if len(actual_lang_list) != len(pdf_file_names):
              # å¦‚æœè¯­è¨€åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè¯­è¨€æˆ–é»˜è®¤"ch"
              actual_lang_list = [actual_lang_list[0] if actual_lang_list else "ch"] * len(pdf_file_names)
  
          # è°ƒç”¨ç®€åŒ–çš„å¼‚æ­¥å¤„ç†å‡½æ•°
          await aio_do_parse_simple(
              output_dir=unique_dir,
              pdf_file_names=pdf_file_names,
              pdf_bytes_list=pdf_bytes_list,
              p_lang_list=actual_lang_list,
              backend=backend,
              parse_method=parse_method,
              formula_enable=formula_enable,
              table_enable=table_enable,
              server_url=server_url,
              f_draw_layout_bbox=False,
              f_draw_span_bbox=False,
              f_dump_md=return_md,
              f_dump_middle_json=return_middle_json,
              f_dump_model_output=return_model_output,
              f_dump_orig_pdf=False,
              f_dump_content_list=return_content_list,
              start_page_id=start_page_id,
              end_page_id=end_page_id,
              **config
          )
  
          # æ ¹æ® response_format_zip å†³å®šè¿”å›ç±»å‹
          if response_format_zip:
              zip_fd, zip_path = tempfile.mkstemp(suffix=".zip", prefix="mineru_results_")
              os.close(zip_fd) 
              with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
                  for pdf_name in pdf_file_names:
                      safe_pdf_name = sanitize_filename(pdf_name)
                      # ç›´æ¥åœ¨unique_dirä¸‹æŸ¥æ‰¾æ–‡ä»¶ï¼Œä¸å†ä½¿ç”¨å¤æ‚çš„å­ç›®å½•ç»“æ„
                      parse_dir = unique_dir
  
                      if not os.path.exists(parse_dir):
                          continue
  
                      # å†™å…¥æ–‡æœ¬ç±»ç»“æœ
                      if return_md:
                          path = os.path.join(parse_dir, f"{pdf_name}.md")
                          if os.path.exists(path):
                              zf.write(path, arcname=os.path.join(safe_pdf_name, f"{safe_pdf_name}.md"))
  
                      if return_middle_json:
                          path = os.path.join(parse_dir, f"{pdf_name}_middle.json")
                          if os.path.exists(path):
                              zf.write(path, arcname=os.path.join(safe_pdf_name, f"{safe_pdf_name}_middle.json"))
  
                      if return_model_output:
                          if backend.startswith("pipeline"):
                              path = os.path.join(parse_dir, f"{pdf_name}_model.json")
                          else:
                              path = os.path.join(parse_dir, f"{pdf_name}_model_output.txt")
                          if os.path.exists(path): 
                              zf.write(path, arcname=os.path.join(safe_pdf_name, os.path.basename(path)))
  
                      if return_content_list:
                          path = os.path.join(parse_dir, f"{pdf_name}_content_list.json")
                          if os.path.exists(path):
                              zf.write(path, arcname=os.path.join(safe_pdf_name, f"{safe_pdf_name}_content_list.json"))
  
                      # å†™å…¥å›¾ç‰‡
                      if return_images:
                          images_dir = os.path.join(parse_dir, "images")
                          image_paths = glob.glob(os.path.join(glob.escape(images_dir), "*.jpg"))
                          for image_path in image_paths:
                              zf.write(image_path, arcname=os.path.join(safe_pdf_name, "images", os.path.basename(image_path)))
  
              return FileResponse(
                  path=zip_path,
                  media_type="application/zip",
                  filename="results.zip",
                  background=BackgroundTask(cleanup_file, zip_path)
              )
          else:
              # æ„å»º JSON ç»“æœ
              result_dict = {}
              for pdf_name in pdf_file_names:
                  result_dict[pdf_name] = {}
                  data = result_dict[pdf_name]
  
                  # ç›´æ¥åœ¨unique_dirä¸‹æŸ¥æ‰¾æ–‡ä»¶ï¼Œä¸å†ä½¿ç”¨å¤æ‚çš„å­ç›®å½•ç»“æ„
                  parse_dir = unique_dir
  
                  if os.path.exists(parse_dir):
                      if return_md:
                          data["md_content"] = get_infer_result(".md", pdf_name, parse_dir)
                      if return_middle_json:
                          data["middle_json"] = get_infer_result("_middle.json", pdf_name, parse_dir)
                      if return_model_output:
                          if backend.startswith("pipeline"):
                              data["model_output"] = get_infer_result("_model.json", pdf_name, parse_dir)
                          else:
                              data["model_output"] = get_infer_result("_model_output.txt", pdf_name, parse_dir)
                      if return_content_list:
                          data["content_list"] = get_infer_result("_content_list.json", pdf_name, parse_dir)
                      if return_images:
                          images_dir = os.path.join(parse_dir, "images")
                          safe_pattern = os.path.join(glob.escape(images_dir), "*.jpg")
                          image_paths = glob.glob(safe_pattern)
                          data["images"] = {
                              os.path.basename(
                                  image_path
                              ): f"data:image/jpeg;base64,{encode_image(image_path)}"
                              for image_path in image_paths
                          }
  
              return JSONResponse(
                  status_code=200,
                  content={
                      "backend": backend,
                      "version": __version__,
                      "results": result_dict,
                      "output_path": unique_dir
                  }
              )
      except Exception as e:
          logger.exception(e)
          return JSONResponse(
              status_code=500,
              content={"error": f"Failed to process file: {str(e)}"}
          )
  
  
  @app.post(path="/file_parse_json",)
  async def parse_pdf_to_json(
          file: UploadFile = File(...),
          lang: str = Form("ch"),
          backend: str = Form("pipeline"),
          parse_method: str = Form("auto"),
          formula_enable: bool = Form(True),
          table_enable: bool = Form(True),
          server_url: Optional[str] = Form(None),
          start_page_id: int = Form(0),
          end_page_id: int = Form(99999),
  ):
      """
      ä¸Šä¼ å•ä¸ªPDFå¹¶è§£æï¼Œè¿”å›markdownå…¨æ–‡ï¼Œä¸å†™å…¥æ–‡ä»¶
      """
      # è·å–å‘½ä»¤è¡Œé…ç½®å‚æ•°
      config = getattr(app.state, "config", {})
  
      try:
          # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
          temp_output_dir = os.path.join(tempfile.gettempdir(), f"mineru_temp_{uuid.uuid4()}")
          os.makedirs(temp_output_dir, exist_ok=True)
  
          try:
              # å¤„ç†ä¸Šä¼ çš„PDFæ–‡ä»¶
              content = await file.read()
              file_path = Path(file.filename)
  
              # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
              temp_path = Path(temp_output_dir) / file_path.name
              with open(temp_path, "wb") as f:
                  f.write(content)
  
              # æ£€æŸ¥æ–‡ä»¶ç±»å‹
              file_suffix = guess_suffix_by_path(temp_path)
              if file_suffix not in pdf_suffixes + image_suffixes:
                  return JSONResponse(
                      status_code=400,
                      content={"error": f"Unsupported file type: {file_suffix}"}
                  )
  
              pdf_bytes = read_fn(temp_path)
              pdf_file_name = file_path.stem
              os.remove(temp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
  
              # è°ƒç”¨ç®€åŒ–çš„å¼‚æ­¥å¤„ç†å‡½æ•°
              await aio_do_parse_simple(
                  output_dir=temp_output_dir,
                  pdf_file_names=[pdf_file_name],
                  pdf_bytes_list=[pdf_bytes],
                  p_lang_list=[lang],
                  backend=backend,
                  parse_method=parse_method,
                  formula_enable=formula_enable,
                  table_enable=table_enable,
                  server_url=server_url,
                  f_draw_layout_bbox=False,
                  f_draw_span_bbox=False,
                  f_dump_md=True,
                  f_dump_middle_json=True,
                  f_dump_model_output=False,
                  f_dump_orig_pdf=False,
                  f_dump_content_list=True,
                  f_dump_images=True,
                  start_page_id=start_page_id,
                  end_page_id=end_page_id,
                  **config
              )
  
              # è¯»å–ç”Ÿæˆçš„markdownå†…å®¹
              md_content = get_infer_result(".md", pdf_file_name, temp_output_dir)
              middle_json = get_infer_result("_middle.json", pdf_file_name, temp_output_dir)
              content_list = get_infer_result("_content_list.json", pdf_file_name, temp_output_dir)
              
              # å¤„ç†å›¾ç‰‡ - è¿‡æ»¤å…¬å¼å›¾ç‰‡ï¼Œè¿”å›å­—å…¸æ ¼å¼
              figure_dict = {}
              images_dir = os.path.join(temp_output_dir, "images")
              if os.path.exists(images_dir):
                  # æ”¶é›†å¸¸è§å›¾ç‰‡æ ¼å¼ï¼Œé¿å…ä»…é™äº .jpg å¯¼è‡´é—æ¼
                  image_paths = []
                  for ext in ("*.jpg", "*.jpeg", "*.png"):
                      safe_pattern = os.path.join(glob.escape(images_dir), ext)
                      image_paths.extend(glob.glob(safe_pattern))
                  for image_path in image_paths:
                      # ä½¿ç”¨ä¿å­˜æ—¶çš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºå›¾ç‰‡æ ‡è¯†ï¼›åº•å±‚å·²å¤„ç†è¿‡æ»¤
                      image_id = os.path.splitext(os.path.basename(image_path))[0]
                      # æ·»åŠ åˆ°å­—å…¸ï¼Œä½¿ç”¨å›¾ç‰‡æ ‡è¯†ä½œä¸ºkeyï¼Œè¿”å›çº¯base64
                      figure_dict[image_id] = encode_image(image_path)
  
              return JSONResponse(
                  status_code=200,
                  content={
                      "filename": pdf_file_name,
                      "md_content": md_content,
                      "middle_json": middle_json,
                      "content_list": content_list,
                      "figure_dict": figure_dict,
                      "backend": backend,
                      "version": __version__
                  }
              )
  
          finally:
              # æ¸…ç†ä¸´æ—¶ç›®å½•
              import shutil
              if os.path.exists(temp_output_dir):
                  shutil.rmtree(temp_output_dir, ignore_errors=True)
  
      except Exception as e:
          logger.exception(e)
          return JSONResponse(
              status_code=500,
              content={"error": f"Failed to process file: {str(e)}"}
          )
  
  
  @app.post(path="/batch_parse",)
  async def batch_parse_pdfs(
          input_path: str = Form(...),
          output_dir: Optional[str] = Form(None),
          lang: str = Form("ch"),
          backend: str = Form("pipeline"),
          parse_method: str = Form("auto"),
          formula_enable: bool = Form(True),
          table_enable: bool = Form(True),
          server_url: Optional[str] = Form(None),
          start_page_id: int = Form(0),
          end_page_id: int = Form(99999),
  ):
      """
      è§£ææŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰PDFï¼ŒæŒ‰é¡ºåºå¤„ç†
      """
      # è·å–å‘½ä»¤è¡Œé…ç½®å‚æ•°
      config = getattr(app.state, "config", {})
  
      try:
          # è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
          if output_dir is None:
              output_dir = "/data/mineru/parsed_output"
          
          # åˆ›å»ºè¾“å‡ºç›®å½•
          os.makedirs(output_dir, exist_ok=True)
  
          # æ£€æŸ¥è¾“å…¥è·¯å¾„
          input_path = Path(input_path)
          if not input_path.exists():
              return JSONResponse(
                  status_code=400,
                  content={"error": f"Input path does not exist: {input_path}"}
              )
  
          # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
          pdf_files = []
          if input_path.is_file():
              # å•ä¸ªæ–‡ä»¶
              if guess_suffix_by_path(input_path) in pdf_suffixes:
                  pdf_files = [input_path]
          else:
              # ç›®å½•ï¼ŒæŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
              for suffix in pdf_suffixes:
                  pdf_files.extend(input_path.glob(f"**/*{suffix}"))
  
          if not pdf_files:
              return JSONResponse(
                  status_code=400,
                  content={"error": "No PDF files found in the specified path"}
              )
  
          # æŒ‰æ–‡ä»¶åæ’åº
          pdf_files.sort()
  
          # å¤„ç†æ¯ä¸ªPDFæ–‡ä»¶
          results = []
          for pdf_file in pdf_files:
              try:
                  logger.info(f"Processing: {pdf_file}")
                  
                  # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„UUIDæ–‡ä»¶å¤¹
                  file_uuid = str(uuid.uuid4())
                  file_output_dir = os.path.join(output_dir, file_uuid)
                  os.makedirs(file_output_dir, exist_ok=True)
                  
                  # è¯»å–PDFæ–‡ä»¶
                  pdf_bytes = read_fn(pdf_file)
                  pdf_file_name = pdf_file.stem
  
                  # è°ƒç”¨ç®€åŒ–çš„å¼‚æ­¥å¤„ç†å‡½æ•°
                  await aio_do_parse_simple(
                      output_dir=file_output_dir,
                      pdf_file_names=[pdf_file_name],
                      pdf_bytes_list=[pdf_bytes],
                      p_lang_list=[lang],
                      backend=backend,
                      parse_method=parse_method,
                      formula_enable=formula_enable,
                      table_enable=table_enable,
                      server_url=server_url,
                      f_draw_layout_bbox=False,
                      f_draw_span_bbox=False,
                      f_dump_md=True,
                      f_dump_middle_json=True,
                      f_dump_model_output=False,
                      f_dump_orig_pdf=False,
                      f_dump_content_list=True,
                      start_page_id=start_page_id,
                      end_page_id=end_page_id,
                      **config
                  )
  
                  results.append({
                      "filename": pdf_file_name,
                      "uuid": file_uuid,
                      "output_dir": file_output_dir,
                      "status": "success",
                      "output_files": [
                          f"{pdf_file_name}.md",
                          f"{pdf_file_name}_middle.json",
                          f"{pdf_file_name}_content_list.json"
                      ]
                  })
  
              except Exception as e:
                  logger.error(f"Failed to process {pdf_file}: {str(e)}")
                  results.append({
                      "filename": pdf_file.name,
                      "uuid": file_uuid if 'file_uuid' in locals() else None,
                      "output_dir": file_output_dir if 'file_output_dir' in locals() else None,
                      "status": "failed",
                      "error": str(e)
                  })
  
          return JSONResponse(
              status_code=200,
              content={
                  "message": f"Batch processing completed. Processed {len(pdf_files)} files.",
                  "output_dir": output_dir,
                  "results": results,
                  "backend": backend,
                  "version": __version__
              }
          )
  
      except Exception as e:
          logger.exception(e)
          return JSONResponse(
              status_code=500,
              content={"error": f"Failed to process batch: {str(e)}"}
          )
  
  
  @click.command(context_settings=dict(ignore_unknown_options=True, allow_extra_args=True))
  @click.pass_context
  @click.option('--host', default='127.0.0.1', help='Server host (default: 127.0.0.1)')
  @click.option('--port', default=8003, type=int, help='Server port (default: 8000)')
  @click.option('--reload', is_flag=True, help='Enable auto-reload (development mode)')
  def main(ctx, host, port, reload, **kwargs):
  
      kwargs.update(arg_parse(ctx))
  
      # å°†é…ç½®å‚æ•°å­˜å‚¨åˆ°åº”ç”¨çŠ¶æ€ä¸­
      app.state.config = kwargs
  
      """å¯åŠ¨MinerU FastAPIæœåŠ¡å™¨çš„å‘½ä»¤è¡Œå…¥å£"""
      print(f"Start MinerU FastAPI Service: http://{host}:{port}")
      print("The API documentation can be accessed at the following address:")
      print(f"- Swagger UI: http://{host}:{port}/docs")
      print(f"- ReDoc: http://{host}:{port}/redoc")
  
      uvicorn.run(
          "mineru.cli.fast_api:app",
          host=host,
          port=port,
          reload=reload
      )
  
  
  if __name__ == "__main__":
      main()
  
  ```

# å››ã€ å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææ¥å£

## 1. æ¦‚è§ˆ 

- **API åç§°**: å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPI
- **æ¥å£çŠ¶æ€**: `[ç¨³å®š]`
- **æ¥å£æè¿°**: æä¾›åŸºäº MainScheduler çš„ç«¯åˆ°ç«¯å­¦æœ¯è®ºæ–‡å¤„ç†ç³»ç»Ÿã€‚å®ƒé›†æˆäº†PDFè§£æã€å…ƒæ•°æ®æå–ã€æ‘˜è¦è¯­æ­¥åˆ†æã€è®ºæ–‡è„‰ç»œåˆ†æä»¥åŠå›¾è¡¨æ˜ å°„ç­‰æ ¸å¿ƒåŠŸèƒ½ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›å…¨é¢ã€ç»“æ„åŒ–çš„è®ºæ–‡æ´å¯Ÿã€‚

### åŠŸèƒ½ç‰¹æ€§

- **PDFè§£æ**: è‡ªåŠ¨è§£æPDFæ–‡ä»¶ï¼Œæå–æ–‡æœ¬ã€å›¾è¡¨å’Œå…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€ä½œè€…ç­‰ï¼‰ã€‚
- **è„‰ç»œåˆ†æ**: æŒ‰ç…§å­¦æœ¯è®ºæ–‡ç»“æ„æå–äº”å¤§æ ¸å¿ƒè„‰ç»œå†…å®¹ã€‚
- **æ‘˜è¦æå–**: æ™ºèƒ½æå–æ‘˜è¦ä¸­çš„å››ä¸ªå…³é”®è¯­æ­¥ï¼ˆèƒŒæ™¯ã€æ–¹æ³•ã€åˆ›æ–°ç‚¹ã€å±€é™ï¼‰ã€‚
- **å›¾è¡¨æ˜ å°„**: å°†å›¾è¡¨æŒ‰æ‰€å±è„‰ç»œåˆ†ç±»å¹¶å»ºç«‹æ˜ å°„å…³ç³»ã€‚
- **å¹¶è¡Œå¤„ç†**: å¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œï¼Œæé«˜å¤„ç†æ•ˆç‡ã€‚
- **å¥åº·æ£€æŸ¥**: å†…ç½®å¥åº·çŠ¶æ€æ£€æŸ¥æ¥å£ï¼Œæ–¹ä¾¿ç›‘æ§ã€‚

## 2. æ ¸å¿ƒæ¥å£: /paper_vis

æ­¤æ¥å£æ˜¯ç³»ç»Ÿçš„ä¸»è¦å…¥å£ï¼Œæ¥æ”¶ä¸€ä¸ªPDFæ–‡ä»¶ï¼Œæ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ï¼Œå¹¶è¿”å›ç»“æ„åŒ–çš„JSONç»“æœã€‚**<u>ï¼ˆå¯ç›´æ¥è¯»å–å®¢æˆ·ç«¯çš„æœ¬åœ°æ–‡ä»¶ï¼‰</u>**

### 2.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8004/paper_vis`
- **è¯·æ±‚å‚æ•°**
  - è¯·æ±‚ä½“ä¸º `multipart/form-data`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å | ç±»å‹ | æ˜¯å¦å¿…å¡« | æè¿°                    |
| ------ | ---- | -------- | ----------------------- |
| `file` | File | æ˜¯       | ç”¨æˆ·ä¸Šä¼ çš„å•ä¸ªPDFæ–‡ä»¶ã€‚ |

- **å¤‡ç”¨è¯·æ±‚æ–¹å¼**:
  - é™¤äº†ä¸Šä¼ æ–‡ä»¶ï¼Œæ¥å£ä¹Ÿæ”¯æŒé€šè¿‡JSONæŒ‡å®š**æœåŠ¡å™¨æœ¬åœ°**çš„æ–‡ä»¶è·¯å¾„è¿›è¡Œåˆ†æã€‚
  - **Endpoint**: `POST http://10.3.35.21:8004/paper_vis`
  - **Headers**: `Content-Type: application/json`
  - **Body**: `{"pdf_path": "/path/on/server/to/paper.pdf"}`

### 2.2. å“åº” 

- **æˆåŠŸå“åº” **

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "success": true,
      "metadata": {
        "title": "HYPOSPACE: EVALUATING LLM CREATIVITY AS SET-VALUED HYPOTHESIS GENERATORS UNDER UNDERDETERMINATION",
        "authors": ["ä½œè€…1", "ä½œè€…2", "ä½œè€…3"]
      },
      "abstract": {
        "background_problem": "èƒŒæ™¯å’Œé—®é¢˜æè¿°",
        "method_approach": "æ–¹æ³•å’Œé€”å¾„",
        "Innovation": "åˆ›æ–°ç‚¹",
        "Limitation/Future Work": "å±€é™å’Œæœªæ¥å·¥ä½œ"
      },
      "lanes": {
        "Context & Related Work": "ç›¸å…³å·¥ä½œå’ŒèƒŒæ™¯å†…å®¹",
        "Methodology & Setup": "æ–¹æ³•è®ºå’Œè®¾ç½®å†…å®¹",
        "Results & Analysis": "ç»“æœå’Œåˆ†æå†…å®¹",
        "Conclusion": "ç»“è®ºå†…å®¹",
        "Innovation Discovery": "å­¦æœ¯åˆ›æ–°æœºä¼šå‘ç°"
      },
      "figure_map": {
        "Context & Related Work": [
          {
            "figure_id": "fig1",
            "caption": "å›¾è¡¨æ ‡é¢˜",
            "content": "ç›¸å…³æ–‡æœ¬å†…å®¹"
          }
        ],
        "Results & Analysis": [
          {
            "figure_id": "fig2",
            "caption": "ç»“æœå›¾è¡¨",
            "content": "ç»“æœç›¸å…³æ–‡æœ¬"
          }
        ]
      },
      "pdf_info": {
        "file_path": "/path/to/paper.pdf",
        "file_size": 1234567,
        "page_count": 10
      },
      "processing_info": {
        "steps_completed": ["pdf_parsing", "abstract_steps", "lane_extraction", "figure_mapping", "final_json_generation"],
        "total_time": 22.54,
        "success": true
      },
      "raw_data": {
        "md_content_length": 50000,
        "content_list_count": 150,
        "figure_dict_count": 8
      }
    
    ```

## 3. è¾…åŠ©æ¥å£

ç”¨äºç›‘æ§æœåŠ¡çš„å¥åº·å’Œè¿è¡ŒçŠ¶æ€ã€‚

### 3.1. GET /health

- **åŠŸèƒ½**: æ£€æŸ¥æœåŠ¡æ˜¯å¦å¥åº·ï¼Œèƒ½å¦å“åº”è¯·æ±‚ã€‚

- **Endpoint**: `GET http://10.3.35.21:8004/health`

- **å“åº”**:

  ```shell
  {
    "status": "healthy",
    "timestamp": "2025-01-27T10:30:00Z"
  }
  ```

### 3.2. GET /status

- **åŠŸèƒ½**: è·å–æœåŠ¡çš„è¯¦ç»†çŠ¶æ€ä¿¡æ¯ï¼Œå¦‚ç‰ˆæœ¬å·ã€è¿è¡Œæ—¶é•¿ã€‚

- **Endpoint**: `GET http://10.3.35.21:8004/status`

- **å“åº”**:

  ```shell
  {
    "status": "running",
    "uptime": 3600,
    "version": "1.0.0"
  }
  ```

## 4. è°ƒç”¨ç¤ºä¾‹

### 4.1. Python è¯·æ±‚

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIæµ‹è¯•å®¢æˆ·ç«¯
æµ‹è¯•æ–‡ä»¶ä¸Šä¼ æ¥å£ /paper_vis
"""

import requests
import json
import time
import os


def test_paper_vis_upload():
    """æµ‹è¯• /paper_vis æ–‡ä»¶ä¸Šä¼ æ¥å£"""
    
    # APIæœåŠ¡å™¨åœ°å€
    base_url = "http://10.3.35.21:8004"
    
    # æµ‹è¯•PDFæ–‡ä»¶è·¯å¾„
    test_pdf_path = "/Users/xiaokong/Desktop/2510.15614v1.pdf"
    
    print("ğŸ§ª æµ‹è¯• /paper_vis æ–‡ä»¶ä¸Šä¼ æ¥å£")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_pdf_path):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_pdf_path}")
        return
    
    print(f"ğŸ“„ ä¸Šä¼ æ–‡ä»¶: {test_pdf_path}")
    print("â³ å¼€å§‹åˆ†æ...")
    
    start_time = time.time()
    
    try:
        # å‡†å¤‡æ–‡ä»¶ä¸Šä¼ 
        with open(test_pdf_path, 'rb') as f:
            files = {
                'file': (os.path.basename(test_pdf_path), f, 'application/pdf')
            }
            
            response = requests.post(
                f"{base_url}/paper_vis",
                files=files,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
        
        end_time = time.time()
        duration = end_time - start_time
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… è®ºæ–‡åˆ†ææˆåŠŸ")
            print(f"â±ï¸ æ€»è€—æ—¶: {duration:.2f}ç§’")
            print(f"ğŸ“Š å¤„ç†ç»“æœ:")
            print(f"   - æˆåŠŸçŠ¶æ€: {result.get('success', False)}")
            print(f"   - å¤„ç†æ—¶é—´: {result.get('total_time', 0):.2f}ç§’")
            
            if result.get('success'):
                print(f"   - è®ºæ–‡æ ‡é¢˜: {result.get('metadata', {}).get('title', 'N/A')}")
                authors = result.get('metadata', {}).get('authors', [])
                print(f"   - ä½œè€…æ•°é‡: {len(authors) if authors else 0}")
                lanes = result.get('lanes', {})
                print(f"   - æ³³é“æ•°é‡: {len(lanes) if lanes else 0}")
                figure_map = result.get('figure_map', {})
                total_figures = sum(len(figures) for figures in figure_map.values()) if figure_map else 0
                print(f"   - å›¾è¡¨æ€»æ•°: {total_figures}")
                
                # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                output_file = "paper_vis_upload_result.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        else:
            print(f"âŒ è®ºæ–‡åˆ†æå¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
            
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰")
    except Exception as e:
        print(f"âŒ è®ºæ–‡åˆ†æå¼‚å¸¸: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ æµ‹è¯•å®Œæˆ")


def test_server_health():
    """æµ‹è¯•æœåŠ¡å™¨å¥åº·çŠ¶æ€"""
    base_url = "http://10.3.35.21:8004"
    
    try:
        # ç›´æ¥æµ‹è¯• /paper_vis æ¥å£çš„OPTIONSè¯·æ±‚
        response = requests.options(f"{base_url}/paper_vis", timeout=10)
        if response.status_code in [200, 405]:  # 405è¡¨ç¤ºæ–¹æ³•ä¸å…è®¸ï¼Œä½†æ¥å£å­˜åœ¨
            print("âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
            return True
        else:
            print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹APIæµ‹è¯•")
    print("=" * 60)
    
    # é¦–å…ˆæµ‹è¯•æœåŠ¡å™¨å¥åº·çŠ¶æ€
    if test_server_health():
        print("\n" + "=" * 60)
        # æµ‹è¯•æ–‡ä»¶ä¸Šä¼ æ¥å£
        test_paper_vis_upload()
    else:
        print("âŒ æœåŠ¡å™¨ä¸å¯ç”¨ï¼Œè¯·å…ˆå¯åŠ¨APIæœåŠ¡å™¨")
        print("   è¿è¡Œå‘½ä»¤: python api_server.py")
```

### 4.2. cURL ç¤ºä¾‹

```shell
# æ–¹å¼ä¸€ï¼šä¸Šä¼ æœ¬åœ°æ–‡ä»¶è¿›è¡Œåˆ†æ
curl -X POST "[http://10.3.35.21:8004/paper_vis](http://10.3.35.21:8004/paper_vis)" \
  -F "file=@/path/to/your/paper.pdf"

# æ–¹å¼äºŒï¼šåˆ†ææœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶
curl -X POST "[http://10.3.35.21:8004/paper_vis](http://10.3.35.21:8004/paper_vis)" \
  -H "Content-Type: application/json" \
  -d '{"pdf_path": "/path/on/server/to/paper.pdf"}'

# æ£€æŸ¥å¥åº·çŠ¶æ€
curl -X GET "[http://10.3.35.21:8004/health](http://10.3.35.21:8004/health)"
```

### 4.3. JavaScript (Fetch API) ç¤ºä¾‹

```javascript
/**
 * è®ºæ–‡åˆ†æAPIå®¢æˆ·ç«¯
 */

// APIåŸºç¡€URL - ä½¿ç”¨ä»£ç†è·¯å¾„é¿å…CORSé—®é¢˜
const API_BASE_URL = process.env.NODE_ENV === 'development' ? '/api' : 'http://10.3.35.21:8004'

/**
 * ä¸Šä¼ PDFæ–‡ä»¶å¹¶è¿›è¡Œåˆ†æ
 * @param {File} pdfFile - PDFæ–‡ä»¶å¯¹è±¡
 * @param {Function} onProgress - è¿›åº¦å›è°ƒå‡½æ•°
 * @returns {Promise<Object>} åˆ†æç»“æœ
 */
export async function analyzePaper(pdfFile, onProgress = null) {
  try {
    console.log('ğŸš€ å¼€å§‹è®ºæ–‡åˆ†æ...')
    console.log('ğŸ“„ æ–‡ä»¶ä¿¡æ¯:', {
      name: pdfFile.name,
      size: pdfFile.size,
      type: pdfFile.type
    })

    // éªŒè¯æ–‡ä»¶ç±»å‹
    if (pdfFile.type !== 'application/pdf') {
      throw new Error('è¯·é€‰æ‹©PDFæ–‡ä»¶')
    }

    // åˆ›å»ºFormData
    const formData = new FormData()
    formData.append('file', pdfFile)

    // æ˜¾ç¤ºè¿›åº¦
    if (onProgress) {
      onProgress(10, 'å‡†å¤‡ä¸Šä¼ æ–‡ä»¶...')
    }

    const startTime = Date.now()

    // å‘é€è¯·æ±‚åˆ° /paper_vis æ¥å£
    const response = await fetch(`${API_BASE_URL}/paper_vis`, {
      method: 'POST',
      body: formData,
      mode: 'cors', // æ˜ç¡®æŒ‡å®šCORSæ¨¡å¼
      headers: {
        // ä¸è®¾ç½®Content-Typeï¼Œè®©æµè§ˆå™¨è‡ªåŠ¨è®¾ç½®multipart/form-data
      },
      // æ³¨æ„ï¼šfetchä¸æ”¯æŒè¿›åº¦å›è°ƒï¼Œè¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿè¿›åº¦
    })

    const endTime = Date.now()
    const duration = (endTime - startTime) / 1000

    if (!response.ok) {
      throw new Error(`æœåŠ¡å™¨é”™è¯¯: ${response.status} ${response.statusText}`)
    }

    const result = await response.json()

    console.log('âœ… è®ºæ–‡åˆ†æå®Œæˆ')
    console.log('â±ï¸ æ€»è€—æ—¶:', duration.toFixed(2), 'ç§’')
    console.log('ğŸ“Š å¤„ç†ç»“æœ:', result)

    // éªŒè¯è¿”å›ç»“æœ
    if (!result.success) {
      throw new Error(result.error || 'åˆ†æå¤±è´¥')
    }

    // æ˜¾ç¤ºæœ€ç»ˆè¿›åº¦
    if (onProgress) {
      onProgress(100, 'åˆ†æå®Œæˆï¼')
    }

    return {
      success: true,
      data: result,
      duration: duration,
      metadata: {
        title: result.metadata?.title || 'æœªçŸ¥æ ‡é¢˜',
        authors: result.metadata?.authors || [],
        totalTime: result.total_time || duration,
        lanesCount: Object.keys(result.lanes || {}).length,
        figuresCount: Object.values(result.figure_map || {}).reduce((total, figures) => total + figures.length, 0)
      }
    }

  } catch (error) {
    console.error('âŒ è®ºæ–‡åˆ†æå¤±è´¥:', error)
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯CORSé”™è¯¯
    let errorMessage = error.message || 'æœªçŸ¥é”™è¯¯'
    if (error.message.includes('CORS') || error.message.includes('Failed to fetch')) {
      errorMessage = 'è·¨åŸŸè¯·æ±‚è¢«é˜»æ­¢ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡å™¨CORSé…ç½®æˆ–ä½¿ç”¨ä»£ç†'
    }
    
    // æ˜¾ç¤ºé”™è¯¯è¿›åº¦
    if (onProgress) {
      onProgress(0, `åˆ†æå¤±è´¥: ${errorMessage}`)
    }

    return {
      success: false,
      error: errorMessage,
      data: null
    }
  }
}

/**
 * æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€
 * @returns {Promise<boolean>} æœåŠ¡å™¨æ˜¯å¦å¯ç”¨
 */
export async function checkServerHealth() {
  try {
    const response = await fetch(`${API_BASE_URL}/paper_vis`, {
      method: 'OPTIONS',
      timeout: 10000
    })
    
    // 200æˆ–405éƒ½è¡¨ç¤ºæ¥å£å­˜åœ¨
    return response.status === 200 || response.status === 405
  } catch (error) {
    console.warn('æœåŠ¡å™¨å¥åº·æ£€æŸ¥å¤±è´¥:', error)
    return false
  }
}

/**
 * æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°ï¼ˆå› ä¸ºfetchä¸æ”¯æŒè¿›åº¦å›è°ƒï¼‰
 * @param {Function} onProgress - è¿›åº¦å›è°ƒå‡½æ•°
 * @param {number} duration - é¢„è®¡æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
 */
export function simulateProgress(onProgress) {
  let progress = 0
  const interval = setInterval(() => {
    progress += Math.random() * 10
    if (progress >= 90) {
      progress = 90
      clearInterval(interval)
    }
    
    const statuses = [
      'æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...',
      'PDFè§£æä¸­...',
      'å†…å®¹æŠ½å–ä¸­...',
      'è¯­ä¹‰åˆ†æä¸­...',
      'ç”Ÿæˆç»“æœä¸­...'
    ]
    
    const statusIndex = Math.floor((progress / 100) * statuses.length)
    const status = statuses[Math.min(statusIndex, statuses.length - 1)]
    
    onProgress(Math.floor(progress), status)
  }, 1000)

  return interval
}

```

## 5. æ³¨æ„äº‹é¡¹

1. **æ–‡ä»¶è·¯å¾„**: ä½¿ç”¨JSONè¯·æ±‚æ—¶ï¼Œè¯·ç¡®ä¿ `pdf_path` æ˜¯æœåŠ¡å™¨å¯è®¿é—®çš„ç»å¯¹è·¯å¾„ã€‚
2. **å¤„ç†æ—¶é—´**: å¤§å‹æˆ–å¤æ‚çš„PDFè®ºæ–‡å¯èƒ½éœ€è¦è¾ƒé•¿çš„å¤„ç†æ—¶é—´ï¼Œå®¢æˆ·ç«¯åº”è®¾ç½®è¶³å¤Ÿé•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆå»ºè®®2åˆ†é’Ÿä»¥ä¸Šï¼‰ã€‚
3. **æ–‡ä»¶æ ¼å¼**: ç›®å‰ä»…æ”¯æŒæ ‡å‡†çš„PDFæ ¼å¼æ–‡ä»¶ã€‚

## è¿ç»´ç¬”è®°

- **æ¥å£ç«¯å£**: `8004`

- **é…ç½®é¡¹åœ°å€**: `/etc/systemd/system/paper-vis-api.service`

- **ä»£ç ä½ç½®**: `/data/kongyb/paper_vis/paper_vis/api_server.py`

- **æ¥å£æºä»£ç **:

  ```python
  #!/usr/bin/env python3
  # -*- coding: utf-8 -*-
  """
  FastAPI æœåŠ¡å™¨ - å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææ¥å£
  åŸºäº MainScheduler çš„å®Œæ•´è®ºæ–‡å¤„ç†ç³»ç»Ÿ
  
  å”¯ä¸€æ¥å£ï¼š
  POST /paper_vis
  - è¾“å…¥ï¼šä¸Šä¼ PDFæ–‡ä»¶
  - è¾“å‡ºï¼šMainSchedulerçš„å®Œæ•´JSONç»“æœ
  """
  from fastapi.middleware.cors import CORSMiddleware
  from fastapi import FastAPI, HTTPException, UploadFile, File
  import uvicorn
  
  # å¯¼å…¥ä¸»è°ƒåº¦å™¨
  from MainScheduler import MainScheduler
  
  
  # åˆ›å»ºFastAPIåº”ç”¨
  app = FastAPI(
      title="å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPI",
      description="åŸºäºAIçš„å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æç³»ç»Ÿ",
      version="1.0.0"
  )
  
  origins = ["*"]
  
  # å°† CORS ä¸­é—´ä»¶æ·»åŠ åˆ°ä½ çš„åº”ç”¨ä¸­
  app.add_middleware(
      CORSMiddleware,
      allow_origins=origins,  # ä½¿ç”¨æ–°çš„ origins åˆ—è¡¨
      allow_credentials=True,
      allow_methods=["*"],
      allow_headers=["*"],
  )
  
  @app.post("/paper_vis")
  async def paper_vis(file: UploadFile = File(...)):
      """
      åˆ†æPDFè®ºæ–‡ - å”¯ä¸€æ¥å£
      
      è¾“å…¥ï¼š
      - file: ä¸Šä¼ çš„PDFæ–‡ä»¶
      
      è¾“å‡ºï¼š
      - MainSchedulerçš„å®Œæ•´JSONç»“æœ
      """
      try:
          print(f"ğŸš€ å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {file.filename}")
          
          # æ£€æŸ¥æ–‡ä»¶ç±»å‹
          if not file.filename.lower().endswith('.pdf'):
              raise HTTPException(
                  status_code=400, 
                  detail="åªæ”¯æŒPDFæ–‡ä»¶æ ¼å¼"
              )
          
          # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹
          file_content = await file.read()
          
          # åˆ›å»ºä¸»è°ƒåº¦å™¨å®ä¾‹
          scheduler = MainScheduler()
          
          # æ‰§è¡Œå®Œæ•´çš„è®ºæ–‡åˆ†ææµç¨‹ï¼ˆç›´æ¥ä½¿ç”¨æ–‡ä»¶å†…å®¹ï¼Œä¸ä¿å­˜åˆ°æœåŠ¡å™¨ï¼‰
          result = scheduler.process_uploaded_pdf(file_content, file.filename)
          
          return result
              
      except Exception as e:
          print(f"âŒ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}")
          raise HTTPException(
              status_code=500,
              detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"
          )
  
  
  if __name__ == "__main__":
      print("ğŸš€ å¯åŠ¨å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPIæœåŠ¡å™¨...")
      print("ğŸ“¡ æœåŠ¡åœ°å€: http://10.3.35.21:8004")
      print("ğŸ“Š å”¯ä¸€æ¥å£: POST /paper_vis")
      print("=" * 60)
      
      # å¯åŠ¨æœåŠ¡å™¨
      uvicorn.run(
          "api_server:app",
          host="0.0.0.0",
          port=8004,
          reload=True,
          log_level="info"
      )
  ```

  # äº”ã€ å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææœåŠ¡å¹³å° 

  ## 1. æ¦‚è§ˆ

  - **å¹³å°åç§°**: å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææœåŠ¡å¹³å°
  - **å¹³å°çŠ¶æ€**: `[ç¨³å®š]`
  - **å¹³å°æè¿°**: æœ¬å¹³å°æ˜¯â€œå­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPIâ€çš„å¯è§†åŒ–å‰ç«¯ç•Œé¢ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªä¾¿æ·çš„å›¾å½¢åŒ–æ“ä½œçª—å£ï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ PDFæ–‡ä»¶ï¼Œå¹¶ç›´è§‚åœ°æŸ¥çœ‹åˆ†æç»“æœã€‚

  ![50a3614bcb6612ad37ba3bce27bfd143](/Users/xiaokong/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_e0erez0j9yre22_7560/temp/RWTemp/2025-10/50a3614bcb6612ad37ba3bce27bfd143.png)

  ![7f5bea41e11b370867ebba38be801295](/Users/xiaokong/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_e0erez0j9yre22_7560/temp/RWTemp/2025-10/7f5bea41e11b370867ebba38be801295.png)

  ![338bb8e07c311fcc83a19cebbf1fbd44](/Users/xiaokong/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_e0erez0j9yre22_7560/temp/RWTemp/2025-10/338bb8e07c311fcc83a19cebbf1fbd44.png)

  ## 2. è®¿é—®åœ°å€

  - **å¹³å°è®¿é—®é“¾æ¥**:
    - `http://10.3.35.21:8080/upload`

  ## 3. æ³¨æ„äº‹é¡¹

  1. **æµè§ˆå™¨å…¼å®¹æ€§**: å»ºè®®ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„ Chrome, Firefox, æˆ– Edge æµè§ˆå™¨ä»¥è·å¾—æœ€ä½³ä½“éªŒã€‚
  2. **æ–‡ä»¶ä¸Šä¼ **: ç”¨æˆ·é€šè¿‡æ­¤å¹³å°ä¸Šä¼ çš„PDFæ–‡ä»¶ï¼Œå°†ç”±åç«¯â€œå­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPIâ€ (`http://10.3.35.21:8004`) è¿›è¡Œå¤„ç†ã€‚
  3. **ç½‘ç»œç¯å¢ƒ**: è¯·ç¡®ä¿å®¢æˆ·ç«¯èƒ½å¤Ÿè®¿é—®æœåŠ¡å™¨ `10.3.35.21` çš„ `8080` ç«¯å£ã€‚

  ## è¿ç»´è®°å½•

  - **æœåŠ¡ç«¯å£**: `8080`

  - **WebæœåŠ¡å™¨é…ç½®**: `/etc/nginx/sites-enabled/paper-vis-frontend`

  - **é¡¹ç›®ä»£ç ä½ç½®**: `/data/kongyb/paper_vis/frontend/`

    

    
