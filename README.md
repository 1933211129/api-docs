# ä¸€ã€ Qwen-VL å›¾åƒè¯†åˆ«æ¥å£

## 1. æ¦‚è§ˆ

- **API åç§°**: Qwen-VL å›¾åƒè¯†åˆ«æ¥å£ (qwen-VL-7B)
- **æ¥å£çŠ¶æ€**: `[ç¨³å®š]`
- **æ¥å£æè¿°**: æä¾›åŸºäº Qwen-VL-7B å¤§æ¨¡å‹çš„å›¾æ–‡å¯¹è¯èƒ½åŠ›ã€‚ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼Œå¹¶é™„å¸¦ä¸€ä¸ªé—®é¢˜ï¼ˆPromptï¼‰ï¼Œæ¥å£å°†è¿”å›æ¨¡å‹å¯¹è¯¥é—®é¢˜çš„æ–‡æœ¬å›ç­”ã€‚

## 2. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8000/v1/image/recognize`
- **è¯·æ±‚å¤´ (Headers)**
  - è¯¥æ¥å£ä½¿ç”¨ `multipart/form-data` æ ¼å¼è¿›è¡Œæ–‡ä»¶ä¸Šä¼ ï¼Œ`requests` åº“ä¼šè‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½® `Content-Type`ã€‚
- **è¯·æ±‚å‚æ•° (Parameters)**
  - è¯·æ±‚ä½“ä¸º `multipart/form-data`ï¼ŒåŒ…å«ä»¥ä¸‹ä¸¤ä¸ªå­—æ®µï¼š

| å‚æ•°å   | ç±»å‹   | æ˜¯å¦å¿…å¡« | æè¿°                                                         |
| -------- | ------ | -------- | ------------------------------------------------------------ |
| `image`  | File   | æ˜¯       | ç”¨æˆ·ä¸Šä¼ çš„åŸå§‹å›¾ç‰‡æ–‡ä»¶ã€‚æ”¯æŒ `png`, `jpg`, `jpeg` ç­‰å¸¸è§æ ¼å¼ã€‚ |
| `prompt` | string | æ˜¯       | ç”¨æˆ·å¯¹å›¾ç‰‡æå‡ºçš„é—®é¢˜æˆ–æŒ‡ä»¤ï¼Œä¾‹å¦‚ "è¿™å¼ å›¾é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"ã€‚        |

## 3. å“åº”

#### æˆåŠŸå“åº”

- **HTTP çŠ¶æ€ç **: `200 OK`
- **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

```shell
{
  "status": "success",
  "result": "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†ä¸€åªçŒ«æ­£èººåœ¨æ¡Œå­ä¸Šç¡è§‰ï¼Œæ—è¾¹æ”¾ç€ä¸€ä¸ªç¬”è®°æœ¬ç”µè„‘ã€‚"
}
```

#### å¤±è´¥å“åº” 

- **HTTP çŠ¶æ€ç **: `400 Bad Request`

  - **åŸå› **: ä¸Šä¼ çš„æ–‡ä»¶éå›¾ç‰‡ç±»å‹ã€‚

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "detail": "ä¸Šä¼ çš„æ–‡ä»¶å¿…é¡»æ˜¯å›¾ç‰‡ç±»å‹ï¼Œä½†æ”¶åˆ°çš„æ˜¯ application/octet-streamã€‚"
    }
    ```

- **HTTP çŠ¶æ€ç **: `500 Internal Server Error`

  - **åŸå› **: æœåŠ¡å™¨æ¨¡å‹åŠ è½½å¤±è´¥ã€æ¨ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ç­‰ã€‚

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "detail": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: [å…·ä½“çš„é”™è¯¯ä¿¡æ¯]"
    }
    ```

## 4. Python è°ƒç”¨ç¤ºä¾‹

```python
import requests
import os
import mimetypes

# ======================== é…ç½® ========================
# !!! è¯·ä¿®æ”¹ä¸ºæœåŠ¡å™¨çš„æ­£ç¡®IPåœ°å€
SERVER_IP = "10.3.35.21"
# !!! è¯·ä¿®æ”¹ä¸ºä½ æœ¬åœ°æµ‹è¯•å›¾ç‰‡çš„è·¯å¾„
IMAGE_PATH = "/path/to/your/local/image.png"
# =======================================================

API_URL = f"http://{SERVER_IP}:8000/v1/image/recognize"

def call_recognition_api(image_path: str, prompt: str):
    """
    è°ƒç”¨å›¾æ–‡è¯†åˆ«API
    :param image_path: æœ¬åœ°å›¾ç‰‡æ–‡ä»¶çš„è·¯å¾„
    :param prompt: å‘æ¨¡å‹æå‡ºçš„é—®é¢˜
    """
    if not os.path.exists(image_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶: {image_path}")
        return

    print(f"å‡†å¤‡å‘æœåŠ¡å™¨ {API_URL} å‘é€è¯·æ±‚...")
    print(f"å›¾ç‰‡: {image_path}")
    print(f"é—®é¢˜: {prompt}")

    # 1. çŒœæµ‹æ–‡ä»¶çš„MIMEç±»å‹ (ä¾‹å¦‚ 'image/png')
    content_type, _ = mimetypes.guess_type(image_path)
    if content_type is None:
        # å¦‚æœæ— æ³•çŒœæµ‹ï¼Œæä¾›ä¸€ä¸ªé»˜è®¤å€¼
        content_type = 'application/octet-stream'
    print(f"å·²è¯†åˆ«å›¾ç‰‡ç±»å‹ä¸º: {content_type}")
    # ---------------------------------------------

    try:
        with open(image_path, 'rb') as image_file:
            # æ ¼å¼ä¸º: (æ–‡ä»¶å, æ–‡ä»¶å¯¹è±¡, Content-Type)
            files = {'image': (os.path.basename(image_path), image_file, content_type)}
            data = {'prompt': prompt}

            # æ³¨æ„ï¼štimeout=60ï¼Œå› ä¸ºVLæ¨¡å‹æ¨ç†å¯èƒ½è¾ƒæ…¢
            response = requests.post(API_URL, files=files, data=data, timeout=60)

            if response.status_code == 200:
                result = response.json()
                print("\n--- âœ… è¯·æ±‚æˆåŠŸ ---")
                print("æ¨¡å‹è¿”å›çš„è¯†åˆ«ç»“æœ:")
                print(result.get('result'))
            else:
                print(f"\n--- âŒ è¯·æ±‚å¤±è´¥ ---")
                print(f"æœåŠ¡å™¨è¿”å›çŠ¶æ€ç : {response.status_code}")
                print(f"é”™è¯¯è¯¦æƒ…: {response.text}")

    except requests.exceptions.Timeout:
        print(f"\n--- âŒ è¯·æ±‚è¶…æ—¶ ---")
        print("è¯·æ±‚è¶…è¿‡60ç§’æœªæ”¶åˆ°å“åº”ï¼ŒæœåŠ¡å™¨å¯èƒ½æ­£åœ¨å¤„ç†æˆ–è´Ÿè½½è¾ƒé«˜ã€‚")
    except requests.exceptions.RequestException as e:
        print(f"\n--- âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸ ---")
        print(f"å…·ä½“é”™è¯¯: {e}")

if __name__ == "__main__":
    # åœ¨è¿™é‡Œä¿®æ”¹ä½ çš„é—®é¢˜
    question = "è¿™å¼ å›¾é‡Œæœ‰ä»€ä¹ˆï¼Ÿè¯·ç”¨ä¸­æ–‡æè¿°ä¸€ä¸‹ã€‚"
    call_recognition_api(IMAGE_PATH, question)
```

## 5. æ³¨æ„äº‹é¡¹

1. **è¶…æ—¶æ—¶é—´**ï¼šè¿™æ˜¯ä¸€ä¸ª GPU å¯†é›†å‹ä»»åŠ¡ï¼Œæ¨¡å‹æ¨ç†å¯èƒ½éœ€è¦å‡ ç§’åˆ°å‡ åç§’ã€‚å®¢æˆ·ç«¯è°ƒç”¨æ—¶ï¼Œ`timeout` å‚æ•°å»ºè®®è®¾ç½®ä¸º **60ç§’** æˆ–æ›´é«˜ï¼Œä»¥é˜²è¯·æ±‚è¶…æ—¶ã€‚
2. **å›¾ç‰‡å¤§å°**ï¼šè¯·å°½é‡é¿å…ä¸Šä¼ è¶…å¤§åˆ†è¾¨ç‡ï¼ˆå¦‚ 8Kï¼‰æˆ–ä½“ç§¯è¿‡å¤§ï¼ˆå¦‚ > 20MBï¼‰çš„å›¾ç‰‡ï¼Œä»¥å…å¯¼è‡´æœåŠ¡å™¨å¤„ç†è¶…æ—¶æˆ–å†…å­˜æº¢å‡ºã€‚
3. **å¹¶å‘é™åˆ¶**ï¼šä¸å»ºè®®è¶…è¿‡ 4 ä¸ªå¹¶å‘è¯·æ±‚ã€‚

## è¿ç»´è®°å½•

- **æ¥å£ç«¯å£**: `8000`
- **é…ç½®é¡¹åœ°å€**: `/etc/systemd/system/qwen_vl_api.service`
- **ä»£ç ä½ç½®**: `/data/wangmeng/qwen_llm_api/qwen_vl/qwen_vl.py`
- **æ¥å£æºä»£ç **:

```python
# -------------------------------------------------------------------------
# Qwen3-VL (8B) å›¾æ–‡è¯†åˆ« API æœåŠ¡
# -------------------------------------------------------------------------
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import torch
import uvicorn
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
import os
import uuid
import logging
from modelscope import Qwen3VLForConditionalGeneration, AutoProcessor
from typing import Optional

# ======================== å…¨å±€é…ç½® ========================
MODEL_PATH = "/data/LLM/Qwen/Qwen3-VL-8B-Instruct"
TEMP_IMAGE_DIR = "/data/wangmeng/qwen_vl"
API_PORT = 8000
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# ==========================================================

model = None
processor = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global model, processor
    os.makedirs(TEMP_IMAGE_DIR, exist_ok=True)
    logging.info(f"å›¾ç‰‡ä¸´æ—¶ç›®å½•å·²ç¡®è®¤: {TEMP_IMAGE_DIR}")
    logging.info(f"å¼€å§‹åŠ è½½æ¨¡å‹: {MODEL_PATH} ...")
    model = Qwen3VLForConditionalGeneration.from_pretrained(MODEL_PATH, dtype="auto", device_map="auto")
    processor = AutoProcessor.from_pretrained(MODEL_PATH)
    logging.info("æ¨¡å‹åŠ è½½æˆåŠŸï¼ŒAPIæœåŠ¡å‡†å¤‡å°±ç»ªï¼")
    yield
    model = None
    processor = None
    torch.cuda.empty_cache()
    logging.info("æ¨¡å‹èµ„æºå·²é‡Šæ”¾ã€‚")

app = FastAPI(lifespan=lifespan)
# ==================== CORSé…ç½® ====================
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# ==========================================================

@app.post("/v1/image/recognize", summary="å•è½®å›¾æ–‡è¯†åˆ«")
async def recognize_image(
    prompt: str = Form(...),
    image: UploadFile = File(...)
):
    logging.info("--- è¯·æ±‚å·²è¿›å…¥å¤„ç†å‡½æ•° ---")
    if image is None:
        logging.error("ä¸¥é‡é”™è¯¯ï¼š'image' å‚æ•°ä¸º Noneï¼")
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨æœªèƒ½æ­£ç¡®è§£æå›¾ç‰‡æ–‡ä»¶ã€‚")

    logging.info(f"æ¥æ”¶åˆ°çš„ 'image' å¯¹è±¡ç±»å‹: {type(image)}")
    logging.info(f"å›¾ç‰‡æ–‡ä»¶å: {image.filename}, å›¾ç‰‡ç±»å‹: {image.content_type}")

    if not image.content_type or not image.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail=f"ä¸Šä¼ çš„æ–‡ä»¶å¿…é¡»æ˜¯å›¾ç‰‡ç±»å‹ï¼Œä½†æ”¶åˆ°çš„æ˜¯ {image.content_type}ã€‚")

    temp_file_path = None
    try:
        # 1. ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡
        file_ext = os.path.splitext(image.filename)[1]
        temp_file_path = os.path.join(TEMP_IMAGE_DIR, f"{uuid.uuid4()}{file_ext}")
        content = await image.read()
        with open(temp_file_path, "wb") as f:
            f.write(content)
        logging.info(f"æ¥æ”¶åˆ°è¯·æ±‚ -> Prompt: '{prompt}', å›¾ç‰‡å·²ä¿å­˜è‡³: {temp_file_path}")

        # 2. æ„å»º messages
        messages = [{"role": "user", "content": [{"type": "image", "image": temp_file_path}, {"type": "text", "text": prompt}]}]

        # 3. æ¨ç†
        inputs = processor.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_dict=True, return_tensors="pt").to(model.device)
        generated_ids = model.generate(**inputs, max_new_tokens=1024)

        # 4. è§£ç 
        generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]
        output_text = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)
        response_text = output_text[0] if output_text else ""
        logging.info(f"æ¨¡å‹è¿”å›ç»“æœ -> {response_text[:100]}...")

        return {"status": "success", "result": response_text}

    except Exception as e:
        logging.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

    finally:
        # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)
            logging.info(f"æ¸…ç†å®Œæ¯• -> ä¸´æ—¶æ–‡ä»¶å·²åˆ é™¤: {temp_file_path}")

if __name__ == "__main__":
    logging.info(f"å¯åŠ¨æœåŠ¡ï¼Œç›‘å¬ [http://0.0.0.0](http://0.0.0.0):{API_PORT}")
    uvicorn.run(app, host="0.0.0.0", port=API_PORT)
```

# äºŒã€ Qwen-Coder ä»£ç ç”Ÿæˆæ¥å£

## 1. æ¦‚è§ˆ

- **API åç§°**: Qwen-Coder ä»£ç ç”Ÿæˆæ¥å£ (Qwen-Coder-30B)
- **æ¥å£çŠ¶æ€**: `[ç¨³å®š]`
- **æ¥å£æè¿°**: æä¾›åŸºäº Qwen-Coder-30B å¤§æ¨¡å‹çš„ä»£ç ç”Ÿæˆä¸å¯¹è¯èƒ½åŠ›ã€‚å®ƒæ”¯æŒä¸¤ç§ç‹¬ç«‹çš„è°ƒç”¨æ¨¡å¼ï¼š
  1. **å•è½®ä»£ç ç”Ÿæˆ**: ç”¨äºä¸€æ¬¡æ€§çš„ä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œç›´æ¥è¿”å›å®Œæ•´ç»“æœã€‚
  2. **æµå¼å¤šè½®å¯¹è¯**: ç”¨äºéœ€è¦ä¸Šä¸‹æ–‡è®°å¿†çš„è¿ç»­å¯¹è¯ï¼Œå®æ—¶è¿”å›ç”Ÿæˆå†…å®¹ã€‚

## 2. æ¥å£ 1: å•è½®ä»£ç ç”Ÿæˆ

æ­¤æ¥å£é€‚ç”¨äºç‹¬ç«‹çš„ã€æ— ä¸Šä¸‹æ–‡å…³è”çš„ä»£ç ç”Ÿæˆè¯·æ±‚ã€‚

### 2.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8001/v1/code/generate`
- **è¯·æ±‚å‚æ•°**
  - è¯·æ±‚ä½“ä¸º `application/x-www-form-urlencoded`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å   | ç±»å‹   | æ˜¯å¦å¿…å¡« | æè¿°                                                |
| -------- | ------ | -------- | --------------------------------------------------- |
| `prompt` | string | æ˜¯       | å…·ä½“çš„ä»£ç ç”ŸæˆæŒ‡ä»¤ï¼Œä¾‹å¦‚ "ç”¨Pythonå†™ä¸€ä¸ªå†’æ³¡æ’åº"ã€‚ |

### 2.2. å“åº” 

- **æˆåŠŸå“åº”**

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "status": "success",
      "result": "def bubble_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        for j in range(0, n-i-1):\n            if arr[j] > arr[j+1]:\n                arr[j], arr[j+1] = arr[j+1], arr[j]"
    }
    ```

- **å¤±è´¥å“åº”**

  - **HTTP çŠ¶æ€ç **: `500 Internal Server Error`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```
    {
      "detail": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: [å…·ä½“çš„é”™è¯¯ä¿¡æ¯]"
    }
    ```

### 2.3. Python è°ƒç”¨ç¤ºä¾‹

```python
import requests

SERVER_URL = "[http://10.3.35.21:8001](http://10.3.35.21:8001)"
API_ENDPOINT = f"{SERVER_URL}/v1/code/generate"

PROMPT = "ç”¨ Python å†™ä¸€ä¸ªæœ€åŸºç¡€ç‰ˆçš„å†’æ³¡æ’åºç®—æ³•ï¼Œåªå†™å‡½æ•°ä½“å³å¯ï¼Œä¸å¿…å†™æµ‹è¯•ä»£ç å’Œç¤ºä¾‹"

def call_single_generation():
    """è°ƒç”¨å•è½®ä»£ç ç”Ÿæˆæ¥å£"""
    print("="*60)
    print(f"ğŸš€ æ­£åœ¨å‘å•è½®æ¥å£å‘é€è¯·æ±‚...")
    print(f"ğŸ“ æŒ‡ä»¤: {PROMPT}")
    print("="*60)

    try:
        # æ„é€ è¯·æ±‚æ•°æ®
        data = {'prompt': PROMPT}
        # Coderæ¨¡å‹æ¨ç†è¾ƒæ…¢ï¼Œè®¾ç½®é•¿è¶…æ—¶
        response = requests.post(API_ENDPOINT, data=data, timeout=360)

        if response.status_code == 200:
            result = response.json()
            print("âœ… è¯·æ±‚æˆåŠŸï¼æ¨¡å‹è¿”å›çš„å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š")
            print("-" * 60)
            print(result.get('result'))
            print("-" * 60)
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥ï¼")
            print(f"  - çŠ¶æ€ç : {response.status_code}")
            print(f"  - é”™è¯¯ä¿¡æ¯: {response.text}")

    except requests.exceptions.RequestException as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸ï¼è¯·æ£€æŸ¥æœåŠ¡å™¨åœ°å€æˆ–ç½‘ç»œè¿æ¥ã€‚")
        print(f"  - é”™è¯¯è¯¦æƒ…: {e}")

if __name__ == "__main__":
    call_single_generation()
```

## 3. æ¥å£ 2: æµå¼å¤šè½®ä»£ç å¯¹è¯

æ­¤æ¥å£é€‚ç”¨äºéœ€è¦è¿ç»­å¯¹è¯ã€ä¿æŒä¸Šä¸‹æ–‡è®°å¿†çš„åœºæ™¯ï¼Œå¹¶ä»¥æµå¼æ–¹å¼å®æ—¶è¿”å›ç»“æœã€‚

### 3.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8001/v1/code/chat_stream`
- **è¯·æ±‚å‚æ•° **
  - è¯·æ±‚ä½“ä¸º `application/x-www-form-urlencoded`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å            | ç±»å‹   | æ˜¯å¦å¿…å¡« | æè¿°                                                         |
| ----------------- | ------ | -------- | ------------------------------------------------------------ |
| `prompt`          | string | æ˜¯       | å½“å‰è½®æ¬¡çš„å¯¹è¯å†…å®¹ã€‚                                         |
| `conversation_id` | string | å¦       | ä¼šè¯IDã€‚**é¦–æ¬¡è¯·æ±‚æ—¶æ— éœ€æä¾›**ï¼ŒæœåŠ¡å™¨ä¼šè‡ªåŠ¨åˆ›å»ºå¹¶è¿”å›ã€‚**åç»­è¯·æ±‚å¿…é¡»æºå¸¦æ­¤ID**ä»¥ç»´æŒä¸Šä¸‹æ–‡ã€‚ |

### 3.2. å“åº”

- **HTTP çŠ¶æ€ç **: `200 OK`
- **å“åº”æ ¼å¼**: `text/event-stream`
  - **é¦–æ¬¡è¯·æ±‚**: å“åº”æµçš„å¼€å¤´ä¼šåŒ…å«ä¼šè¯IDï¼Œæ ¼å¼ä¸º `conversation_id:[UUID]\n---\n`ï¼Œç´§æ¥ç€æ˜¯æ¨¡å‹ç”Ÿæˆçš„å†…å†…å®¹ã€‚å®¢æˆ·ç«¯éœ€è¦è§£æå¹¶ä¿å­˜æ­¤IDç”¨äºåç»­å¯¹è¯ã€‚
  - **åç»­è¯·æ±‚**: å“åº”æµåªåŒ…å«æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ã€‚

### 3.3. Python è°ƒç”¨ç¤ºä¾‹ 

```python
import requests
import time

SERVER_URL = "[http://10.3.35.21:8001](http://10.3.35.21:8001)"
API_ENDPOINT = f"{SERVER_URL}/v1/code/chat_stream"

def call_streaming_chat_session():
    """æ¼”ç¤ºä¸€ä¸ªå®Œæ•´çš„æµå¼å¤šè½®å¯¹è¯"""
    conversation_id = None

    # --- ç¬¬ä¸€è½®å¯¹è¯ï¼šç”ŸæˆPythonä»£ç  ---
    prompt1 = "ç”¨ Python å†™ä¸€ä¸ªæœ€åŸºç¡€ç‰ˆçš„å†’æ³¡æ’åºç®—æ³•ï¼Œåªå†™å‡½æ•°ä½“å³å¯ï¼Œä¸å¿…å†™æµ‹è¯•ä»£ç å’Œç¤ºä¾‹"
    print("="*60)
    print(f"ğŸš€ [ç¬¬ä¸€è½®] æ­£åœ¨å‘æµå¼æ¥å£å‘é€è¯·æ±‚...")
    print(f"ğŸ“ ä½ : {prompt1}")
    print("="*60)
    print("ğŸ¤– AI: ", end="", flush=True)

    try:
        data = {'prompt': prompt1}
        with requests.post(API_ENDPOINT, data=data, stream=True, timeout=360) as response:
            if response.status_code == 200:
                header_processed = False
                for chunk in response.iter_content(chunk_size=None, decode_unicode=True):
                    if not header_processed and "conversation_id:" in chunk:
                        parts = chunk.split("\n---\n", 1)
                        header = parts[0]
                        conversation_id = header.replace("conversation_id:", "").strip()
                        print(f"\n[ç³»ç»Ÿæç¤ºï¼šå·²å»ºç«‹ä¼šè¯, ID: {conversation_id}]\n")
                        print("ğŸ¤– AI: ", end="", flush=True)
                        if len(parts) > 1: print(parts[1], end="", flush=True)
                        header_processed = True
                        continue
                    print(chunk, end="", flush=True)
                print("\n") # å®Œæ•´å›ç­”ç»“æŸåæ¢è¡Œ
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code}, é”™è¯¯: {response.text}")
                return # å¦‚æœç¬¬ä¸€è½®å¤±è´¥ï¼Œåˆ™ç»ˆæ­¢
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
        return

    time.sleep(1)

    # --- ç¬¬äºŒè½®å¯¹è¯ï¼šå°†Pythonä»£ç è½¬ä¸ºJava ---
    if not conversation_id:
        print("âŒ æœªèƒ½è·å–ä¼šè¯IDï¼Œæ— æ³•è¿›è¡Œç¬¬äºŒè½®å¯¹è¯ã€‚")
        return

    prompt2 = "éå¸¸å¥½ã€‚ç°åœ¨ï¼Œè¯·æŠŠä¸Šé¢è¿™æ®µ Python ä»£ç æ— ç¼åœ°è½¬æ¢æˆåŠŸèƒ½å®Œå…¨ç­‰æ•ˆçš„ Java ä»£ç ã€‚"
    print("="*60)
    print(f"ğŸš€ [ç¬¬äºŒè½®] æ­£åœ¨ç»§ç»­å¯¹è¯...")
    print(f"ğŸ“ ä½ : {prompt2}")
    print("="*60)
    print("ğŸ¤– AI: ", end="", flush=True)

    try:
        data = {'prompt': prompt2, 'conversation_id': conversation_id}
        with requests.post(API_ENDPOINT, data=data, stream=True, timeout=360) as response:
            if response.status_code == 200:
                for chunk in response.iter_content(chunk_size=None, decode_unicode=True):
                    # ç¬¬äºŒè½®ä¸å†éœ€è¦å¤„ç†IDï¼Œç›´æ¥æ‰“å°
                    if "conversation_id:" in chunk and "---" in chunk: continue
                    print(chunk, end="", flush=True)
                print("\n")
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code}, é”™è¯¯: {response.text}")
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")

if __name__ == "__main__":
    call_streaming_chat_session()
```

## 4. æ³¨æ„äº‹é¡¹

1. **è¶…æ—¶æ—¶é—´**ï¼šCoder-30B æ¨¡å‹è¾ƒå¤§ï¼Œæ¨ç†è€—æ—¶è¾ƒé•¿ã€‚å®¢æˆ·ç«¯è°ƒç”¨æ—¶ï¼Œ`timeout` å‚æ•°å»ºè®®è®¾ç½®ä¸º **360ç§’** æˆ–æ›´é«˜ã€‚
2. **ä¼šè¯ç®¡ç†**ï¼šæµå¼å¯¹è¯çš„ä¸Šä¸‹æ–‡ä¿å­˜åœ¨æœåŠ¡å™¨å†…å­˜ä¸­ã€‚å¦‚æœæœåŠ¡é‡å¯ï¼Œæ‰€æœ‰ä¼šè¯å†å²å°†ä¸¢å¤±ã€‚

##  è¿ç»´ç¬”è®°

- **æ¥å£ç«¯å£**: `8001`
- **é…ç½®é¡¹åœ°å€**: `/etc/systemd/system/qwen_coder_api.service`
- **ä»£ç ä½ç½®**: `/data/wangmeng/qwen_llm_api/qwen_coder/qwen_coder_api.py`
- **æ¥å£æºä»£ç **:

```python
# -------------------------------------------------------------------------
# Qwen3-Coder-30B API æœåŠ¡
# åŠŸèƒ½: æä¾›å•è½®ä»£ç ç”Ÿæˆå’Œæµå¼å¤šè½®ä»£ç å¯¹è¯èƒ½åŠ›
# åŠ è½½æ–¹å¼: ä½¿ç”¨åŸç”Ÿ Transformers ä»æœ¬åœ°è·¯å¾„åŠ è½½
# -------------------------------------------------------------------------

import torch
import uvicorn
from fastapi import FastAPI, Form, HTTPException
from fastapi.responses import StreamingResponse
from contextlib import asynccontextmanager
import uuid
import logging
from typing import List, Dict, Optional
from threading import Thread
from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer

# ======================== å…¨å±€é…ç½® ========================
# 1. æ¨¡å‹æœ¬åœ°ç»å¯¹è·¯å¾„
MODEL_PATH = "/data/LLM/Qwen/qwen3-coder-30b-a3b-instruct-local/"

# 2. API æœåŠ¡ç›‘å¬ç«¯å£
API_PORT = 8001

# 3. æ¨¡å‹ç”Ÿæˆå‚æ•°
GENERATION_CONFIG = {
    "max_new_tokens": 4096,
    "temperature": 0.7,
    "top_p": 0.8,
    "top_k": 20,
    "repetition_penalty": 1.05
}

# 4. æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# ==========================================================

# --- å…¨å±€å˜é‡å®šä¹‰ ---
model = None
tokenizer = None
conversation_histories: Dict[str, List] = {}

# --- FastAPI åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç† ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    global model, tokenizer
    logging.info(f"å¼€å§‹åŠ è½½æ¨¡å‹: {MODEL_PATH} ...")
    logging.info("è¿™å°†å ç”¨çº¦ 75GB æ˜¾å­˜ï¼Œè¯·ç¡®ä¿ç¡¬ä»¶èµ„æºå……è¶³ã€‚")

    # ä½¿ç”¨ transformers çš„åŠ è½½å™¨ï¼Œå®ƒèƒ½æ­£ç¡®å¤„ç†æœ¬åœ°è·¯å¾„
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_PATH,
        local_files_only=True,
        trust_remote_code=True # å¯¹äºQwenç­‰å¤æ‚æ¨¡å‹ï¼Œå¿…é¡»ä¿¡ä»»å…¶è‡ªå¸¦çš„ä»£ç 
    )
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
        dtype="auto",
        device_map="auto",
        local_files_only=True,
        trust_remote_code=True # å¿…é¡»
    )

    logging.info("æ¨¡å‹åŠ è½½æˆåŠŸï¼ŒCoder APIæœåŠ¡å‡†å¤‡å°±ç»ªï¼")
    yield

    model = None
    tokenizer = None
    torch.cuda.empty_cache()
    logging.info("æ¨¡å‹èµ„æºå·²é‡Šæ”¾ï¼ŒæœåŠ¡å·²å…³é—­ã€‚")

# --- åˆ›å»º FastAPI åº”ç”¨å®ä¾‹ ---
app = FastAPI(lifespan=lifespan)

# ======================== API æ¥å£å®šä¹‰ ========================

# --- æ¥å£ 1: å•è½®ä»£ç ç”Ÿæˆ (Stateless) ---
@app.post("/v1/code/generate", summary="å•è½®ä»£ç ç”Ÿæˆ")
async def generate_code(prompt: str = Form(..., description="å•æ¬¡çš„ä»£ç ç”ŸæˆæŒ‡ä»¤")):
    logging.info(f"[å•è½®è¯·æ±‚] Prompt: {prompt[:100]}...")
    try:
        messages = [{"role": "user", "content": prompt}]
        
        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
        generated_ids = model.generate(**model_inputs, **GENERATION_CONFIG)
        output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()
        result = tokenizer.decode(output_ids, skip_special_tokens=True)
        
        logging.info(f"[å•è½®å“åº”] Result: {result[:100]}...")
        return {"status": "success", "result": result}
    except Exception as e:
        logging.error(f"[å•è½®è¯·æ±‚] å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# --- æ¥å£ 2: æµå¼å¤šè½®ä»£ç å¯¹è¯ (Stateful) ---
@app.post("/v1/code/chat_stream", summary="[æµå¼] å¤šè½®ä»£ç å¯¹è¯")
async def stream_chat_with_coder(
    prompt: str = Form(..., description="å½“å‰è½®æ¬¡çš„å¯¹è¯å†…å®¹"),
    conversation_id: Optional[str] = Form(None, description="ä¼šè¯IDï¼Œç”¨äºç»´æŒä¸Šä¸‹æ–‡")
):
    logging.info(f"[æµå¼è¯·æ±‚] Conv ID: {conversation_id}, Prompt: {prompt[:100]}...")

    if not conversation_id:
        conversation_id = str(uuid.uuid4())
        conversation_histories[conversation_id] = []
        logging.info(f"[æµå¼è¯·æ±‚] åˆ›å»ºæ–°ä¼šè¯: {conversation_id}")

    history = conversation_histories.get(conversation_id, [])
    history.append({"role": "user", "content": prompt})

    text = tokenizer.apply_chat_template(history, tokenize=False, add_generation_prompt=True)
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

    streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

    generation_kwargs = dict(**model_inputs, streamer=streamer, **GENERATION_CONFIG)
    thread = Thread(target=model.generate, kwargs=generation_kwargs)
    thread.start()

    async def stream_generator():
        full_response = ""
        # åœ¨æµçš„å¼€å¤´ï¼Œå…ˆå‘é€ conversation_id å’Œä¸€ä¸ªåˆ†éš”ç¬¦
        yield f"conversation_id:{conversation_id}\n---\n"
        
        for new_text in streamer:
            full_response += new_text
            yield new_text
        
        # ç”Ÿæˆç»“æŸåï¼Œå°†å®Œæ•´çš„å›ç­”å­˜å…¥å†å²è®°å½•
        history.append({"role": "assistant", "content": full_response})
        conversation_histories[conversation_id] = history
        logging.info(f"[æµå¼å“åº”] Conv ID: {conversation_id}, Full Response: {full_response[:100]}...")

    return StreamingResponse(stream_generator(), media_type="text/event-stream")

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    logging.info(f"å¯åŠ¨æœåŠ¡ï¼Œç›‘å¬ [http://0.0.0.0](http://0.0.0.0):{API_PORT}")
    uvicorn.run(app, host="0.0.0.0", port=API_PORT)
```

# ä¸‰ã€ MinerUæ¥å£æ–‡æ¡£

## 1. æ¦‚è§ˆ

- **API åç§°**: MinerU PDF æ–‡æ¡£è§£ææ¥å£
- **æ¥å£çŠ¶æ€**: `[ç¨³å®š]`
- **æ¥å£æè¿°**: æä¾›å¼ºå¤§çš„ PDF æ–‡æ¡£è§£æèƒ½åŠ›ï¼Œæ”¯æŒå°†æ–‡æ¡£è½¬æ¢ä¸º Markdownã€JSON ç­‰å¤šç§æ ¼å¼ï¼Œå¹¶èƒ½æå–è¡¨æ ¼ã€å…¬å¼å’Œå›¾ç‰‡ã€‚æ¥å£åˆ†ä¸ºä¸‰ç§æ¨¡å¼ï¼šä¸Šä¼ è§£æå¹¶ä¿å­˜åˆ°æœåŠ¡å™¨ã€ä¸Šä¼ è§£æç›´æ¥è¿”å› JSONã€å¤„ç†æœåŠ¡å™¨å†…éƒ¨å·²æœ‰çš„æ–‡ä»¶ã€‚

## 2. æ¥å£ 1: /file_parse - å•æ–‡ä»¶è§£æä¿å­˜

æ­¤æ¥å£ç”¨äºä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª PDF æ–‡ä»¶ï¼ŒæœåŠ¡å™¨è§£æåå°†ç»“æœä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚

### 2.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8003/file_parse`
- **è¯·æ±‚å‚æ•° **
  - è¯·æ±‚ä½“ä¸º `multipart/form-data`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å                | ç±»å‹    | æ˜¯å¦å¿…å¡« | é»˜è®¤å€¼                       | æè¿°                                                         |
| --------------------- | ------- | -------- | ---------------------------- | ------------------------------------------------------------ |
| `files`               | File    | æ˜¯       | -                            | ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ã€‚åœ¨ cURL æˆ– Postman ä¸­å¯ä»¥é‡å¤æ­¤å­—æ®µä»¥ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ã€‚ |
| `output_dir`          | string  | å¦       | `/data/mineru/parsed_output` | è§£æç»“æœåœ¨æœåŠ¡å™¨ä¸Šçš„ä¿å­˜ç›®å½•ã€‚                               |
| `lang_list`           | list    | å¦       | `["ch"]`                     | è¯­è¨€åˆ—è¡¨ï¼Œä¾‹å¦‚ `["ch", "en"]`ã€‚                              |
| `backend`             | string  | å¦       | `pipeline`                   | åç«¯è§£æå¼•æ“ç±»å‹ã€‚                                           |
| `parse_method`        | string  | å¦       | `auto`                       | è§£ææ–¹æ³•ã€‚                                                   |
| `formula_enable`      | boolean | å¦       | `true`                       | æ˜¯å¦å¯ç”¨å…¬å¼è¯†åˆ«ã€‚                                           |
| `table_enable`        | boolean | å¦       | `true`                       | æ˜¯å¦å¯ç”¨è¡¨æ ¼è¯†åˆ«ã€‚                                           |
| `return_md`           | boolean | å¦       | `true`                       | æ˜¯å¦ç”Ÿæˆ `.md` æ–‡ä»¶ã€‚                                        |
| `return_middle_json`  | boolean | å¦       | `true`                       | æ˜¯å¦ç”Ÿæˆä¸­é—´è¿‡ç¨‹çš„ `.json` æ–‡ä»¶ã€‚                            |
| `return_content_list` | boolean | å¦       | `true`                       | æ˜¯å¦ç”Ÿæˆå†…å®¹åˆ—è¡¨çš„ `.json` æ–‡ä»¶ã€‚                            |
| `return_images`       | boolean | å¦       | `true`                       | æ˜¯å¦æå–å¹¶ä¿å­˜å›¾ç‰‡ã€‚                                         |
| `response_format_zip` | boolean | å¦       | `false`                      | æ˜¯å¦å°†æ‰€æœ‰è¾“å‡ºæ–‡ä»¶æ‰“åŒ…æˆ ZIP æ ¼å¼è¿”å›ã€‚                      |
| `start_page_id`       | integer | å¦       | `0`                          | è§£æçš„èµ·å§‹é¡µç ã€‚                                             |
| `end_page_id`         | integer | å¦       | `99999`                      | è§£æçš„ç»“æŸé¡µç ã€‚                                             |

### 2.2. å“åº”

- **æˆåŠŸå“åº”**

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
        "message": "Successfully parsed 1 file(s).",
        "output_dir": "/Users/xiaokong/task/2025/paper/backend/uploads/papers"
    }
    ```

- **å¤±è´¥å“åº”**

  - **HTTP çŠ¶æ€ç **: `400 Bad Request` / `500 Internal Server Error`
  - **å“åº”ä½“**: åŒ…å«é”™è¯¯ä¿¡æ¯çš„æ–‡æœ¬æˆ– JSONã€‚

### 2.3. è°ƒç”¨ç¤ºä¾‹

- **Python è¯·æ±‚**

  ```python
  # è¯·æ±‚å•ä¸ªæ–‡ä»¶ï¼Œä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
  # ï¼ˆè‹¥ä¸å†™output_diråˆ™é»˜è®¤ä¿å­˜åˆ°/data/mineru/parsed_output"ï¼‰
  import requests
  import time
  import os
  import sys
  
  # --- é…ç½® ---
  # æœåŠ¡åœ°å€
  SERVER_URL = "http://10.3.35.21:8003/file_parse"
  
  # 1. è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
  PDF_FILE_PATH = "æˆ‘ä»¬ä½äº/pdfsè·¯å¾„ä¸‹çš„ç”¨æˆ·ä¸Šä¼ ç”¨æ—¶é—´é‡å‘½åä¹‹åçš„æ–‡æ¡£"
  # 2. æŒ‡å®šä¿å­˜è·¯å¾„
  output_dir = "/Users/xiaokong/task/2025/paper/backend/uploads/papers"
  # --- é…ç½®ç»“æŸ ---
  print(f"--- å¯åŠ¨ /file_parse  ---")
  print(f"ä¸Šä¼ æ–‡ä»¶: {PDF_FILE_PATH}")
  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
  if not os.path.exists(PDF_FILE_PATH):
      print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¦ä¸Šä¼ çš„æ–‡ä»¶! è·¯å¾„: {PDF_FILE_PATH}")
      sys.exit(1)
  # å‡†å¤‡è¦æäº¤çš„è¡¨å•æ•°æ®
  form_data = {
      'backend': 'pipeline',
      'output_dir':output_dir
    # å…¶ä»–å‚æ•°å¯ä»¥åœ¨è¿™é‡Œé…ç½®
  }
  try:
      with open(PDF_FILE_PATH, 'rb') as f:
          files_to_upload = {
              'files': (os.path.basename(PDF_FILE_PATH), f, 'application/pdf')
          }
          print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...")
          # è®°å½•å¼€å§‹æ—¶é—´
          start_time = time.time()
          # å‘é€ POST è¯·æ±‚
          response = requests.post(SERVER_URL, files=files_to_upload, data=form_data)
          # è®°å½•ç»“æŸæ—¶é—´
          end_time = time.time()
          total_time = end_time - start_time
      # --- åˆ†æå“åº” ---
      if response.status_code == 200:
          print(f"çŠ¶æ€: æˆåŠŸ (200 OK)")
      else:
          print(f"çŠ¶æ€: å¤±è´¥ ({response.status_code})")
          print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
  
  except requests.exceptions.ConnectionError:
      print(f"é”™è¯¯: è¿æ¥è¢«æ‹’ç»ã€‚è¯·ç¡®ä¿ fast_api.py æ­£åœ¨ {SERVER_URL} è¿è¡Œã€‚")
  except Exception as e:
      print(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
  finally:
      print("-" * 30)
      print(f"åç«¯ '/file_parse' æµ‹è¯•ç»“æŸã€‚")
      if 'total_time' in locals():
          print(f"æ€»è¿è¡Œæ—¶é•¿: {total_time:.2f} ç§’")
      print("-" * 30)
  
  ```

- **cURL ç¤ºä¾‹**

  ```shell
  curl -X POST "http://10.3.35.21:8003/file_parse" \
    -F "files=@document1.pdf" \
    -F "output_dir=/custom/output/path" 
  ```

## 3. æ¥å£ 2: /file_parse_json - å•æ–‡ä»¶è§£æè¿”å›JSON

æ­¤æ¥å£ç”¨äºä¸Šä¼ å•ä¸ª PDF æ–‡ä»¶ï¼ŒæœåŠ¡å™¨è§£æåä¸å†™å…¥æ–‡ä»¶ï¼Œè€Œæ˜¯ç›´æ¥åœ¨å“åº”ä½“ä¸­è¿”å›åŒ…å« Markdown å…¨æ–‡ç­‰ä¿¡æ¯çš„ JSON å¯¹è±¡ã€‚

### 3.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8003/file_parse_json`
- **è¯·æ±‚å‚æ•°**
  - `file`: å•ä¸ªPDFæ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
  - å…¶ä»–å‚æ•°ï¼ˆå¦‚ `lang`, `backend` ç­‰ï¼‰ä¸ `/file_parse` æ¥å£ç±»ä¼¼ï¼Œä½†ä¸ºå•æ•°å½¢å¼ï¼ˆä¾‹å¦‚ `lang` è€Œä¸æ˜¯ `lang_list`ï¼‰ã€‚

| å‚æ•°å | ç±»å‹   | æ˜¯å¦å¿…å¡« | é»˜è®¤å€¼ | æè¿°                |
| ------ | ------ | -------- | ------ | ------------------- |
| `file` | File   | æ˜¯       | -      | å•ä¸ªPDFæ–‡ä»¶ã€‚       |
| `lang` | string | å¦       | `ch`   | è¯­è¨€ï¼Œä¾‹å¦‚ `"en"`ã€‚ |

### 3.2. å“åº” 

- **æˆåŠŸå“åº”**

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "filename": "document",
      "md_content": "# æ–‡æ¡£æ ‡é¢˜\n\nè¿™æ˜¯è§£æåçš„markdownå†…å®¹...",
      "middle_json": "{ç‰ˆé¢ä¿¡æ¯}",
      "content_list": "[å†…å®¹åˆ—è¡¨]",
      "figure_dict": {
          "figure_1": "iVBORw0KGgoAAAANSUhEUgA...ï¼ˆbase6ç¼–ç ï¼Œå¯ç›´æ¥è§£æä¸ºå›¾ç‰‡æ–‡ä»¶ï¼‰",
          "figure_2": "R0lGODlhAQABAIAAAAAAAP..."
      },
      "backend": "pipeline",
      "version": "2.5.4"
    }
    ```

### 3.3. è°ƒç”¨ç¤ºä¾‹ 

- **Python è¯·æ±‚**

  ```python
  import requests
  import time
  import os
  import sys
  import json
  
  '''{
    "filename": "document",
    "md_content": "# æ–‡æ¡£æ ‡é¢˜\n\nè¿™æ˜¯è§£æåçš„markdownå†…å®¹...",
    "middle_json": "{...}",
    "content_list": "[...]",
    "figure_dict": {"file_name","base64"},
    "backend": "pipeline",
    "version": "2.5.4"
  }'''
  # --- é…ç½® ---
  # æœåŠ¡åœ°å€
  SERVER_URL = "http://10.3.35.21:8003/file_parse_json"
  
  # 1. è¦ä¸Šä¼ çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„
  PDF_FILE_PATH = "/Users/xiaokong/task/2025/paper_vis/vis/arxiv/1ee8ca1c-3478-4c4f-9b77-379ff4d58982/2dbbabd2678ba74fcd9b08aadae975ae.pdf"
  
  # 2. å¯ä»¥æŠŠè¿”å›çš„JSONç»“æœä¿å­˜åœ¨æœ¬åœ°çš„è¿™ä¸ªæ–‡ä»¶é‡Œï¼Œåœ¨å®é™…ä½¿ç”¨ä¸­ä¹Ÿå¯ä»¥ç›´æ¥å½“ä½œå­—å…¸å˜é‡è¿”å›
  OUTPUT_JSON_PATH = "test_parsejson.json"
  # --- é…ç½®ç»“æŸ ---
  
  print(f"--- å¯åŠ¨ /file_parse_json æµ‹è¯• ---")
  print(f"ä¸Šä¼ æ–‡ä»¶: {PDF_FILE_PATH}")
  print(f"æœ¬åœ°JSONè¾“å‡ºè·¯å¾„: {OUTPUT_JSON_PATH}")
  
  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
  if not os.path.exists(PDF_FILE_PATH):
      print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¦ä¸Šä¼ çš„æ–‡ä»¶! è·¯å¾„: {PDF_FILE_PATH}")
      sys.exit(1)
  
  # å‡†å¤‡è¡¨å•æ•°æ® (ä½¿ç”¨æœåŠ¡å™¨é»˜è®¤å€¼)
  form_data = {
      'backend': 'pipeline'
    # è¿™é‡Œå¯ä»¥å†™å…¶ä»–å‚æ•°
  } 
  
  try:
      # æ‰“å¼€æ–‡ä»¶
      with open(PDF_FILE_PATH, 'rb') as f:
          # 'file' æ˜¯ @app.post å®šä¹‰çš„å­—æ®µå (æ³¨æ„ï¼Œä¸æ˜¯ 'files')
          files_to_upload = {
              'file': (os.path.basename(PDF_FILE_PATH), f, 'application/pdf')
          } 
          print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...")
          # è®°å½•å¼€å§‹æ—¶é—´
          start_time = time.time()
          # å‘é€ POST è¯·æ±‚
          response = requests.post(SERVER_URL, files=files_to_upload, data=form_data)
          # è®°å½•ç»“æŸæ—¶é—´
          end_time = time.time()
          total_time = end_time - start_time
      # --- åˆ†æå“åº” ---
      if response.status_code == 200:
          print(f"çŠ¶æ€: æˆåŠŸ (200 OK)")
          try:
              # 1. è·å–JSONç»“æœ
              result_json = response.json() # å¯ä»¥ç›´æ¥å–å‡ºè¿™ä¸ªå˜é‡ä½¿ç”¨
              print(f"æˆåŠŸä»æœåŠ¡å™¨è·å–JSONç»“æœã€‚")
              
              # 2. å°†ç»“æœå†™å…¥æœ¬åœ°æ–‡ä»¶
              with open(OUTPUT_JSON_PATH, 'w', encoding='utf-8') as f_out:
                  json.dump(result_json, f_out, ensure_ascii=False, indent=4)
              print(f"å·²å°†è¿”å›çš„JSONå†™å…¥åˆ°: {OUTPUT_JSON_PATH}")
              
          except Exception as e:
              print(f"è§£ææˆ–å†™å…¥JSONæ—¶å‡ºé”™: {e}")
      else:
          print(f"çŠ¶æ€: å¤±è´¥ ({response.status_code})")
          print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
  
  except requests.exceptions.ConnectionError:
      print(f"é”™è¯¯: è¿æ¥è¢«æ‹’ç»ã€‚è¯·ç¡®ä¿ fast_api.py æ­£åœ¨ {SERVER_URL} è¿è¡Œã€‚")
  except Exception as e:
      print(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
  
  finally:
      print("-" * 30)
      print(f"åç«¯ '/file_parse_json' æµ‹è¯•ç»“æŸã€‚")
      if 'total_time' in locals():
          print(f"æ€»è¿è¡Œæ—¶é•¿: {total_time:.2f} ç§’")
      print("-" * 30)
  
  ```

  **è§£æå‡ºå®é™…å›¾ç‰‡**ï¼š

  ```python
  import base64
  import os
  
  def decode_and_save_images(fig_dict):
      """
      éå† figure_dictï¼Œå°†å¹²å‡€çš„ Base64 ç¼–ç çš„å›¾ç‰‡æ•°æ®è§£ç ï¼Œå¹¶ç»Ÿä¸€ä¿å­˜ä¸º PNG æ–‡ä»¶ã€‚
  
      æ–‡ä»¶åå–è‡ªå­—å…¸çš„é”® (key)ï¼Œå¹¶æ·»åŠ  .png åç¼€ã€‚
      
      :param fig_dict: å­—å…¸ï¼Œé”®æ˜¯ä¸å¸¦åç¼€çš„æ–‡ä»¶åï¼Œå€¼æ˜¯çº¯ Base64 å­—ç¬¦ä¸²ã€‚
      """
      print("--- å¼€å§‹è§£ç å’Œä¿å­˜å›¾ç‰‡ ---")
  
      # éå†å­—å…¸
      for filename_base, base64_data in fig_dict.items():
          # 1. è®¾ç½®è¾“å‡ºæ–‡ä»¶åï¼Œç»Ÿä¸€ä½¿ç”¨ .png åç¼€
          output_filename = f"{filename_base}.png"
          
          try:
              # æ ¹æ®ç”¨æˆ·è¦æ±‚ï¼ŒBase64 æ•°æ®æ˜¯â€œå¹²å‡€â€çš„ï¼Œç›´æ¥ä½œä¸ºç¼–ç æ•°æ®
              img_encoded_data = base64_data
  
              # 2. è§£ç  Base64 æ•°æ®
              img_data = base64.b64decode(img_encoded_data)
  
              # 3. å†™å…¥æ–‡ä»¶
              with open(output_filename, "wb") as f:
                  f.write(img_data)
              
              print(f"æˆåŠŸä¿å­˜æ–‡ä»¶: {output_filename}")
  
          except Exception as e:
              # æ‰“å°é”™è¯¯ä¿¡æ¯ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
              print(f"é”™è¯¯ï¼šä¿å­˜æ–‡ä»¶ {output_filename} æ—¶å‘ç”Ÿé”™è¯¯ã€‚Base64 æ•°æ®å¯èƒ½æ— æ•ˆã€‚è¯¦ç»†é”™è¯¯: {e}")
  
  if __name__ == "__main__":
      decode_and_save_images(figure_dict)
  
  ```

  

- **cURL ç¤ºä¾‹**

  ```shell
  curl -X POST "http://10.3.35.21:8003/file_parse_json" \
    -F "file=@document.pdf" 
  ```

## 4. æ¥å£ 3: /batch_parse - æ‰¹é‡è§£ææœåŠ¡å™¨å†…æ–‡ä»¶

æ­¤æ¥å£ä¸ä¸Šä¼ æ–‡ä»¶ï¼Œè€Œæ˜¯å¤„ç†æœåŠ¡å™¨æŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰ PDF æ–‡ä»¶ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡çš„ã€é¢„ç½®çš„è§£æä»»åŠ¡ã€‚

### 4.1. è¯·æ±‚ 

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8003/batch_parse`
- **è¯·æ±‚å‚æ•°**
  - è¯·æ±‚ä½“ä¸º `application/x-www-form-urlencoded`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å       | ç±»å‹   | æ˜¯å¦å¿…å¡« | é»˜è®¤å€¼                       | æè¿°                                             |
| ------------ | ------ | -------- | ---------------------------- | ------------------------------------------------ |
| `input_path` | string | æ˜¯       | -                            | **æœåŠ¡å™¨ä¸Š**çš„è¾“å…¥è·¯å¾„ï¼ˆå¯ä»¥æ˜¯å•ä¸ªæ–‡ä»¶æˆ–ç›®å½•ï¼‰ã€‚ |
| `output_dir` | string | å¦       | `/data/mineru/parsed_output` | è§£æç»“æœåœ¨æœåŠ¡å™¨ä¸Šçš„ä¿å­˜ç›®å½•ã€‚                   |

### 4.2. å“åº” 

- **æˆåŠŸå“åº”**

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "message": "Batch processing completed. Processed 2 files.",
      "output_dir": "/data/mineru/parsed_output",
      "results": [
        {
          "filename": "doc1.pdf",
          "status": "success",
          "output_files": ["doc1.md", "doc1_middle.json"]
        },
        {
          "filename": "doc2.pdf",
          "status": "failed",
          "error": "Processing error message"
        }
      ],
      "backend": "pipeline",
      "version": "2.5.4"
    }
    ```

### 4.3. è°ƒç”¨ç¤ºä¾‹

- **Python è¯·æ±‚**

  ```python
  import requests
  import time
  import os
  import sys
  import json
  
  # --- é…ç½® ---
  # æœåŠ¡åœ°å€
  SERVER_URL = "http://10.3.35.21:8003/batch_parse"
  
  # 1. ä½ è¦æœåŠ¡å™¨å¤„ç†çš„ã€æœåŠ¡å™¨æœ¬åœ°ã€‘çš„æ–‡ä»¶å¤¹è·¯å¾„
  INPUT_PATH_ON_SERVER = "/data/kongyb/batch/"
  # --- é…ç½®ç»“æŸ ---
  output_dir = "/data/kongyb/output/"
  print(f"--- å¯åŠ¨ /batch_parse æµ‹è¯• ---")
  print(f"è¯·æ±‚æœåŠ¡å™¨å¤„ç†è·¯å¾„: {INPUT_PATH_ON_SERVER}")
  
  # å‡†å¤‡è¦æäº¤çš„è¡¨å•æ•°æ®
  # è¿™ä¸ªæ¥å£ä¸ä¸Šä¼ æ–‡ä»¶ï¼Œåªå‘é€è¡¨å•å­—æ®µ
  form_data = {
      'input_path': INPUT_PATH_ON_SERVER,
      'backend': 'pipeline',
      'output_dir':output_dir
  }
  try:
      print("æ­£åœ¨å‘é€è¯·æ±‚åˆ°æœåŠ¡å™¨...")
      # è®°å½•å¼€å§‹æ—¶é—´
      start_time = time.time()
      # å‘é€ POST è¯·æ±‚
      response = requests.post(SERVER_URL, data=form_data)
      # è®°å½•ç»“æŸæ—¶é—´
      end_time = time.time()
      total_time = end_time - start_time
  
      # --- åˆ†æå“åº” ---
      if response.status_code == 200:
          print(f"çŠ¶æ€: æˆåŠŸ (200 OK)")
          print("æœåŠ¡å™¨è¿”å›çš„æ‰¹é‡å¤„ç†æŠ¥å‘Š:")
      else:
          print(f"çŠ¶æ€: å¤±è´¥ ({response.status_code})")
          print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
  except requests.exceptions.ConnectionError:
      print(f"é”™è¯¯: è¿æ¥è¢«æ‹’ç»ã€‚è¯·ç¡®ä¿ fast_api.py æ­£åœ¨ {SERVER_URL} è¿è¡Œã€‚")
  except Exception as e:
      print(f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
  finally:
      print("-" * 30)
      print(f"åç«¯ '/batch_parse' æµ‹è¯•ç»“æŸã€‚")
      if 'total_time' in locals():
          print(f"æ€»è¿è¡Œæ—¶é•¿: {total_time:.2f} ç§’")
      print("-" * 30)
  ```

- **cURL ç¤ºä¾‹**

  ```shell
  curl -X POST "http://10.3.35.21:8003/batch_parse" \
    -F "input_path=/path/to/pdf/directory" \
    -F "output_dir=/custom/output/path" 
  ```

## 5. æ³¨æ„äº‹é¡¹

1. **ç¦æ­¢å¹¶å‘è¯·æ±‚**ï¼šæ­¤æœåŠ¡ä¸ºé‡åº¦ I/O å’Œ CPU/GPU å¯†é›†å‹ä»»åŠ¡ï¼Œå¹¶å‘è¯·æ±‚å¯èƒ½å¯¼è‡´å†…å­˜å ç”¨è¿‡é«˜ä¸”é€Ÿåº¦æ›´æ…¢ã€‚**<u>è¯·åŠ¡å¿…æŒ‰é¡ºåºã€å•ä¸ªåœ°å‘é€è¯·æ±‚ã€‚</u>**
2. **é•¿è¶…æ—¶è®¾ç½®**ï¼šPDF è§£ææ˜¯è€—æ—¶æ“ä½œï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§æ–‡ä»¶ã€‚å®¢æˆ·ç«¯åœ¨è°ƒç”¨æ—¶ï¼Œ`timeout` å‚æ•°åº”è®¾ç½®ä¸ºä¸€ä¸ªè¾ƒå¤§çš„å€¼ï¼ˆä¾‹å¦‚ 120ç§’æˆ–æ›´é«˜ï¼‰ã€‚

## è¿ç»´è®°å½•

- **æ¥å£ç«¯å£**: `8003`

- **é…ç½®é¡¹åœ°å€**: `/etc/systemd/system/mineru-api.service`

- **ä»£ç ä½ç½®**: `/data/wangmeng/anaconda3/envs/vllm/lib/python3.11/site-packages/mineru/cli/fast_api.py`

- **æ¥å£æºä»£ç **:

  ```python
  import uuid
  import os
  import re
  import tempfile
  import asyncio
  import uvicorn
  import click
  import zipfile
  from pathlib import Path
  import glob
  from fastapi import FastAPI, UploadFile, File, Form
  from fastapi.middleware.gzip import GZipMiddleware
  from fastapi.responses import JSONResponse, FileResponse
  from starlette.background import BackgroundTask
  from typing import List, Optional
  from loguru import logger
  from base64 import b64encode
  
  from mineru.cli.common import aio_do_parse, aio_do_parse_simple, read_fn, pdf_suffixes, image_suffixes
  from mineru.utils.cli_parser import arg_parse
  from mineru.utils.guess_suffix_or_lang import guess_suffix_by_path
  from mineru.version import __version__
  
  app = FastAPI()
  app.add_middleware(GZipMiddleware, minimum_size=1000)
  
  
  def sanitize_filename(filename: str) -> str:
      """
      æ ¼å¼åŒ–å‹ç¼©æ–‡ä»¶çš„æ–‡ä»¶å
      ç§»é™¤è·¯å¾„éå†å­—ç¬¦, ä¿ç•™ Unicode å­—æ¯ã€æ•°å­—ã€._- 
      ç¦æ­¢éšè—æ–‡ä»¶
      """
      sanitized = re.sub(r'[/\\\.]{2,}|[/\\]', '', filename)
      sanitized = re.sub(r'[^\w.-]', '_', sanitized, flags=re.UNICODE)
      if sanitized.startswith('.'):
          sanitized = '_' + sanitized[1:]
      return sanitized or 'unnamed'
  
  def cleanup_file(file_path: str) -> None:
      """æ¸…ç†ä¸´æ—¶ zip æ–‡ä»¶"""
      try:
          if os.path.exists(file_path):
              os.remove(file_path)
      except Exception as e:
          logger.warning(f"fail clean file {file_path}: {e}")
  
  def encode_image(image_path: str) -> str:
      """Encode image using base64"""
      with open(image_path, "rb") as f:
          return b64encode(f.read()).decode()
  
  def get_infer_result(file_suffix_identifier: str, pdf_name: str, parse_dir: str) -> Optional[str]:
      """ä»ç»“æœæ–‡ä»¶ä¸­è¯»å–æ¨ç†ç»“æœ"""
      result_file_path = os.path.join(parse_dir, f"{pdf_name}{file_suffix_identifier}")
      if os.path.exists(result_file_path):
          with open(result_file_path, "r", encoding="utf-8") as fp:
              return fp.read()
      return None
  
  
  @app.post(path="/file_parse",)
  async def parse_pdf(
          files: List[UploadFile] = File(...),
          output_dir: Optional[str] = Form(None),
          lang_list: List[str] = Form(["ch"]),
          backend: str = Form("pipeline"),
          parse_method: str = Form("auto"),
          formula_enable: bool = Form(True),
          table_enable: bool = Form(True),
          server_url: Optional[str] = Form(None),
          return_md: bool = Form(True),
          return_middle_json: bool = Form(True),
          return_model_output: bool = Form(False),
          return_content_list: bool = Form(True),
          return_images: bool = Form(False),
          response_format_zip: bool = Form(False),
          start_page_id: int = Form(0),
          end_page_id: int = Form(99999),
  ):
  
      # è·å–å‘½ä»¤è¡Œé…ç½®å‚æ•°
      config = getattr(app.state, "config", {})
  
      try:
          # è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
          if output_dir is None:
              output_dir = "/data/mineru/parsed_output"
          
          # åˆ›å»ºå”¯ä¸€çš„è¾“å‡ºç›®å½•
          unique_dir = os.path.join(output_dir, str(uuid.uuid4()))
          os.makedirs(unique_dir, exist_ok=True)
  
          # å¤„ç†ä¸Šä¼ çš„PDFæ–‡ä»¶
          pdf_file_names = []
          pdf_bytes_list = []
  
          for file in files:
              content = await file.read()
              file_path = Path(file.filename)
  
              # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
              temp_path = Path(unique_dir) / file_path.name
              with open(temp_path, "wb") as f:
                  f.write(content)
  
              # å¦‚æœæ˜¯å›¾åƒæ–‡ä»¶æˆ–PDFï¼Œä½¿ç”¨read_fnå¤„ç†
              file_suffix = guess_suffix_by_path(temp_path)
              if file_suffix in pdf_suffixes + image_suffixes:
                  try:
                      pdf_bytes = read_fn(temp_path)
                      pdf_bytes_list.append(pdf_bytes)
                      pdf_file_names.append(file_path.stem)
                      os.remove(temp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                  except Exception as e:
                      return JSONResponse(
                          status_code=400,
                          content={"error": f"Failed to load file: {str(e)}"}
                      )
              else:
                  return JSONResponse(
                      status_code=400,
                      content={"error": f"Unsupported file type: {file_suffix}"}
                  )
  
  
          # è®¾ç½®è¯­è¨€åˆ—è¡¨ï¼Œç¡®ä¿ä¸æ–‡ä»¶æ•°é‡ä¸€è‡´
          actual_lang_list = lang_list
          if len(actual_lang_list) != len(pdf_file_names):
              # å¦‚æœè¯­è¨€åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªè¯­è¨€æˆ–é»˜è®¤"ch"
              actual_lang_list = [actual_lang_list[0] if actual_lang_list else "ch"] * len(pdf_file_names)
  
          # è°ƒç”¨ç®€åŒ–çš„å¼‚æ­¥å¤„ç†å‡½æ•°
          await aio_do_parse_simple(
              output_dir=unique_dir,
              pdf_file_names=pdf_file_names,
              pdf_bytes_list=pdf_bytes_list,
              p_lang_list=actual_lang_list,
              backend=backend,
              parse_method=parse_method,
              formula_enable=formula_enable,
              table_enable=table_enable,
              server_url=server_url,
              f_draw_layout_bbox=False,
              f_draw_span_bbox=False,
              f_dump_md=return_md,
              f_dump_middle_json=return_middle_json,
              f_dump_model_output=return_model_output,
              f_dump_orig_pdf=False,
              f_dump_content_list=return_content_list,
              start_page_id=start_page_id,
              end_page_id=end_page_id,
              **config
          )
  
          # æ ¹æ® response_format_zip å†³å®šè¿”å›ç±»å‹
          if response_format_zip:
              zip_fd, zip_path = tempfile.mkstemp(suffix=".zip", prefix="mineru_results_")
              os.close(zip_fd) 
              with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
                  for pdf_name in pdf_file_names:
                      safe_pdf_name = sanitize_filename(pdf_name)
                      # ç›´æ¥åœ¨unique_dirä¸‹æŸ¥æ‰¾æ–‡ä»¶ï¼Œä¸å†ä½¿ç”¨å¤æ‚çš„å­ç›®å½•ç»“æ„
                      parse_dir = unique_dir
  
                      if not os.path.exists(parse_dir):
                          continue
  
                      # å†™å…¥æ–‡æœ¬ç±»ç»“æœ
                      if return_md:
                          path = os.path.join(parse_dir, f"{pdf_name}.md")
                          if os.path.exists(path):
                              zf.write(path, arcname=os.path.join(safe_pdf_name, f"{safe_pdf_name}.md"))
  
                      if return_middle_json:
                          path = os.path.join(parse_dir, f"{pdf_name}_middle.json")
                          if os.path.exists(path):
                              zf.write(path, arcname=os.path.join(safe_pdf_name, f"{safe_pdf_name}_middle.json"))
  
                      if return_model_output:
                          if backend.startswith("pipeline"):
                              path = os.path.join(parse_dir, f"{pdf_name}_model.json")
                          else:
                              path = os.path.join(parse_dir, f"{pdf_name}_model_output.txt")
                          if os.path.exists(path): 
                              zf.write(path, arcname=os.path.join(safe_pdf_name, os.path.basename(path)))
  
                      if return_content_list:
                          path = os.path.join(parse_dir, f"{pdf_name}_content_list.json")
                          if os.path.exists(path):
                              zf.write(path, arcname=os.path.join(safe_pdf_name, f"{safe_pdf_name}_content_list.json"))
  
                      # å†™å…¥å›¾ç‰‡
                      if return_images:
                          images_dir = os.path.join(parse_dir, "images")
                          image_paths = glob.glob(os.path.join(glob.escape(images_dir), "*.jpg"))
                          for image_path in image_paths:
                              zf.write(image_path, arcname=os.path.join(safe_pdf_name, "images", os.path.basename(image_path)))
  
              return FileResponse(
                  path=zip_path,
                  media_type="application/zip",
                  filename="results.zip",
                  background=BackgroundTask(cleanup_file, zip_path)
              )
          else:
              # æ„å»º JSON ç»“æœ
              result_dict = {}
              for pdf_name in pdf_file_names:
                  result_dict[pdf_name] = {}
                  data = result_dict[pdf_name]
  
                  # ç›´æ¥åœ¨unique_dirä¸‹æŸ¥æ‰¾æ–‡ä»¶ï¼Œä¸å†ä½¿ç”¨å¤æ‚çš„å­ç›®å½•ç»“æ„
                  parse_dir = unique_dir
  
                  if os.path.exists(parse_dir):
                      if return_md:
                          data["md_content"] = get_infer_result(".md", pdf_name, parse_dir)
                      if return_middle_json:
                          data["middle_json"] = get_infer_result("_middle.json", pdf_name, parse_dir)
                      if return_model_output:
                          if backend.startswith("pipeline"):
                              data["model_output"] = get_infer_result("_model.json", pdf_name, parse_dir)
                          else:
                              data["model_output"] = get_infer_result("_model_output.txt", pdf_name, parse_dir)
                      if return_content_list:
                          data["content_list"] = get_infer_result("_content_list.json", pdf_name, parse_dir)
                      if return_images:
                          images_dir = os.path.join(parse_dir, "images")
                          safe_pattern = os.path.join(glob.escape(images_dir), "*.jpg")
                          image_paths = glob.glob(safe_pattern)
                          data["images"] = {
                              os.path.basename(
                                  image_path
                              ): f"data:image/jpeg;base64,{encode_image(image_path)}"
                              for image_path in image_paths
                          }
  
              return JSONResponse(
                  status_code=200,
                  content={
                      "backend": backend,
                      "version": __version__,
                      "results": result_dict,
                      "output_path": unique_dir
                  }
              )
      except Exception as e:
          logger.exception(e)
          return JSONResponse(
              status_code=500,
              content={"error": f"Failed to process file: {str(e)}"}
          )
  
  
  @app.post(path="/file_parse_json",)
  async def parse_pdf_to_json(
          file: UploadFile = File(...),
          lang: str = Form("ch"),
          backend: str = Form("pipeline"),
          parse_method: str = Form("auto"),
          formula_enable: bool = Form(True),
          table_enable: bool = Form(True),
          server_url: Optional[str] = Form(None),
          start_page_id: int = Form(0),
          end_page_id: int = Form(99999),
  ):
      """
      ä¸Šä¼ å•ä¸ªPDFå¹¶è§£æï¼Œè¿”å›markdownå…¨æ–‡ï¼Œä¸å†™å…¥æ–‡ä»¶
      """
      # è·å–å‘½ä»¤è¡Œé…ç½®å‚æ•°
      config = getattr(app.state, "config", {})
  
      try:
          # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
          temp_output_dir = os.path.join(tempfile.gettempdir(), f"mineru_temp_{uuid.uuid4()}")
          os.makedirs(temp_output_dir, exist_ok=True)
  
          try:
              # å¤„ç†ä¸Šä¼ çš„PDFæ–‡ä»¶
              content = await file.read()
              file_path = Path(file.filename)
  
              # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
              temp_path = Path(temp_output_dir) / file_path.name
              with open(temp_path, "wb") as f:
                  f.write(content)
  
              # æ£€æŸ¥æ–‡ä»¶ç±»å‹
              file_suffix = guess_suffix_by_path(temp_path)
              if file_suffix not in pdf_suffixes + image_suffixes:
                  return JSONResponse(
                      status_code=400,
                      content={"error": f"Unsupported file type: {file_suffix}"}
                  )
  
              pdf_bytes = read_fn(temp_path)
              pdf_file_name = file_path.stem
              os.remove(temp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
  
              # è°ƒç”¨ç®€åŒ–çš„å¼‚æ­¥å¤„ç†å‡½æ•°
              await aio_do_parse_simple(
                  output_dir=temp_output_dir,
                  pdf_file_names=[pdf_file_name],
                  pdf_bytes_list=[pdf_bytes],
                  p_lang_list=[lang],
                  backend=backend,
                  parse_method=parse_method,
                  formula_enable=formula_enable,
                  table_enable=table_enable,
                  server_url=server_url,
                  f_draw_layout_bbox=False,
                  f_draw_span_bbox=False,
                  f_dump_md=True,
                  f_dump_middle_json=True,
                  f_dump_model_output=False,
                  f_dump_orig_pdf=False,
                  f_dump_content_list=True,
                  f_dump_images=True,
                  start_page_id=start_page_id,
                  end_page_id=end_page_id,
                  **config
              )
  
              # è¯»å–ç”Ÿæˆçš„markdownå†…å®¹
              md_content = get_infer_result(".md", pdf_file_name, temp_output_dir)
              middle_json = get_infer_result("_middle.json", pdf_file_name, temp_output_dir)
              content_list = get_infer_result("_content_list.json", pdf_file_name, temp_output_dir)
              
              # å¤„ç†å›¾ç‰‡ - è¿‡æ»¤å…¬å¼å›¾ç‰‡ï¼Œè¿”å›å­—å…¸æ ¼å¼
              figure_dict = {}
              images_dir = os.path.join(temp_output_dir, "images")
              if os.path.exists(images_dir):
                  # æ”¶é›†å¸¸è§å›¾ç‰‡æ ¼å¼ï¼Œé¿å…ä»…é™äº .jpg å¯¼è‡´é—æ¼
                  image_paths = []
                  for ext in ("*.jpg", "*.jpeg", "*.png"):
                      safe_pattern = os.path.join(glob.escape(images_dir), ext)
                      image_paths.extend(glob.glob(safe_pattern))
                  for image_path in image_paths:
                      # ä½¿ç”¨ä¿å­˜æ—¶çš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºå›¾ç‰‡æ ‡è¯†ï¼›åº•å±‚å·²å¤„ç†è¿‡æ»¤
                      image_id = os.path.splitext(os.path.basename(image_path))[0]
                      # æ·»åŠ åˆ°å­—å…¸ï¼Œä½¿ç”¨å›¾ç‰‡æ ‡è¯†ä½œä¸ºkeyï¼Œè¿”å›çº¯base64
                      figure_dict[image_id] = encode_image(image_path)
  
              return JSONResponse(
                  status_code=200,
                  content={
                      "filename": pdf_file_name,
                      "md_content": md_content,
                      "middle_json": middle_json,
                      "content_list": content_list,
                      "figure_dict": figure_dict,
                      "backend": backend,
                      "version": __version__
                  }
              )
  
          finally:
              # æ¸…ç†ä¸´æ—¶ç›®å½•
              import shutil
              if os.path.exists(temp_output_dir):
                  shutil.rmtree(temp_output_dir, ignore_errors=True)
  
      except Exception as e:
          logger.exception(e)
          return JSONResponse(
              status_code=500,
              content={"error": f"Failed to process file: {str(e)}"}
          )
  
  
  @app.post(path="/batch_parse",)
  async def batch_parse_pdfs(
          input_path: str = Form(...),
          output_dir: Optional[str] = Form(None),
          lang: str = Form("ch"),
          backend: str = Form("pipeline"),
          parse_method: str = Form("auto"),
          formula_enable: bool = Form(True),
          table_enable: bool = Form(True),
          server_url: Optional[str] = Form(None),
          start_page_id: int = Form(0),
          end_page_id: int = Form(99999),
  ):
      """
      è§£ææŒ‡å®šè·¯å¾„ä¸‹çš„æ‰€æœ‰PDFï¼ŒæŒ‰é¡ºåºå¤„ç†
      """
      # è·å–å‘½ä»¤è¡Œé…ç½®å‚æ•°
      config = getattr(app.state, "config", {})
  
      try:
          # è®¾ç½®é»˜è®¤è¾“å‡ºç›®å½•
          if output_dir is None:
              output_dir = "/data/mineru/parsed_output"
          
          # åˆ›å»ºè¾“å‡ºç›®å½•
          os.makedirs(output_dir, exist_ok=True)
  
          # æ£€æŸ¥è¾“å…¥è·¯å¾„
          input_path = Path(input_path)
          if not input_path.exists():
              return JSONResponse(
                  status_code=400,
                  content={"error": f"Input path does not exist: {input_path}"}
              )
  
          # æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
          pdf_files = []
          if input_path.is_file():
              # å•ä¸ªæ–‡ä»¶
              if guess_suffix_by_path(input_path) in pdf_suffixes:
                  pdf_files = [input_path]
          else:
              # ç›®å½•ï¼ŒæŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
              for suffix in pdf_suffixes:
                  pdf_files.extend(input_path.glob(f"**/*{suffix}"))
  
          if not pdf_files:
              return JSONResponse(
                  status_code=400,
                  content={"error": "No PDF files found in the specified path"}
              )
  
          # æŒ‰æ–‡ä»¶åæ’åº
          pdf_files.sort()
  
          # å¤„ç†æ¯ä¸ªPDFæ–‡ä»¶
          results = []
          for pdf_file in pdf_files:
              try:
                  logger.info(f"Processing: {pdf_file}")
                  
                  # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„UUIDæ–‡ä»¶å¤¹
                  file_uuid = str(uuid.uuid4())
                  file_output_dir = os.path.join(output_dir, file_uuid)
                  os.makedirs(file_output_dir, exist_ok=True)
                  
                  # è¯»å–PDFæ–‡ä»¶
                  pdf_bytes = read_fn(pdf_file)
                  pdf_file_name = pdf_file.stem
  
                  # è°ƒç”¨ç®€åŒ–çš„å¼‚æ­¥å¤„ç†å‡½æ•°
                  await aio_do_parse_simple(
                      output_dir=file_output_dir,
                      pdf_file_names=[pdf_file_name],
                      pdf_bytes_list=[pdf_bytes],
                      p_lang_list=[lang],
                      backend=backend,
                      parse_method=parse_method,
                      formula_enable=formula_enable,
                      table_enable=table_enable,
                      server_url=server_url,
                      f_draw_layout_bbox=False,
                      f_draw_span_bbox=False,
                      f_dump_md=True,
                      f_dump_middle_json=True,
                      f_dump_model_output=False,
                      f_dump_orig_pdf=False,
                      f_dump_content_list=True,
                      start_page_id=start_page_id,
                      end_page_id=end_page_id,
                      **config
                  )
  
                  results.append({
                      "filename": pdf_file_name,
                      "uuid": file_uuid,
                      "output_dir": file_output_dir,
                      "status": "success",
                      "output_files": [
                          f"{pdf_file_name}.md",
                          f"{pdf_file_name}_middle.json",
                          f"{pdf_file_name}_content_list.json"
                      ]
                  })
  
              except Exception as e:
                  logger.error(f"Failed to process {pdf_file}: {str(e)}")
                  results.append({
                      "filename": pdf_file.name,
                      "uuid": file_uuid if 'file_uuid' in locals() else None,
                      "output_dir": file_output_dir if 'file_output_dir' in locals() else None,
                      "status": "failed",
                      "error": str(e)
                  })
  
          return JSONResponse(
              status_code=200,
              content={
                  "message": f"Batch processing completed. Processed {len(pdf_files)} files.",
                  "output_dir": output_dir,
                  "results": results,
                  "backend": backend,
                  "version": __version__
              }
          )
  
      except Exception as e:
          logger.exception(e)
          return JSONResponse(
              status_code=500,
              content={"error": f"Failed to process batch: {str(e)}"}
          )
  
  
  @click.command(context_settings=dict(ignore_unknown_options=True, allow_extra_args=True))
  @click.pass_context
  @click.option('--host', default='127.0.0.1', help='Server host (default: 127.0.0.1)')
  @click.option('--port', default=8003, type=int, help='Server port (default: 8000)')
  @click.option('--reload', is_flag=True, help='Enable auto-reload (development mode)')
  def main(ctx, host, port, reload, **kwargs):
  
      kwargs.update(arg_parse(ctx))
  
      # å°†é…ç½®å‚æ•°å­˜å‚¨åˆ°åº”ç”¨çŠ¶æ€ä¸­
      app.state.config = kwargs
  
      """å¯åŠ¨MinerU FastAPIæœåŠ¡å™¨çš„å‘½ä»¤è¡Œå…¥å£"""
      print(f"Start MinerU FastAPI Service: http://{host}:{port}")
      print("The API documentation can be accessed at the following address:")
      print(f"- Swagger UI: http://{host}:{port}/docs")
      print(f"- ReDoc: http://{host}:{port}/redoc")
  
      uvicorn.run(
          "mineru.cli.fast_api:app",
          host=host,
          port=port,
          reload=reload
      )
  
  
  if __name__ == "__main__":
      main()
  
  ```

# å››ã€ å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææ¥å£

## 1. æ¦‚è§ˆ 

- **API åç§°**: å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPI
- **æ¥å£çŠ¶æ€**: `[ç¨³å®š]`
- **æ¥å£æè¿°**: æä¾›åŸºäº MainScheduler çš„ç«¯åˆ°ç«¯å­¦æœ¯è®ºæ–‡å¤„ç†ç³»ç»Ÿã€‚å®ƒé›†æˆäº†PDFè§£æã€å…ƒæ•°æ®æå–ã€æ‘˜è¦è¯­æ­¥åˆ†æã€è®ºæ–‡è„‰ç»œåˆ†æä»¥åŠå›¾è¡¨æ˜ å°„ç­‰æ ¸å¿ƒåŠŸèƒ½ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›å…¨é¢ã€ç»“æ„åŒ–çš„è®ºæ–‡æ´å¯Ÿã€‚

### åŠŸèƒ½ç‰¹æ€§

- **PDFè§£æ**: è‡ªåŠ¨è§£æPDFæ–‡ä»¶ï¼Œæå–æ–‡æœ¬ã€å›¾è¡¨å’Œå…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€ä½œè€…ç­‰ï¼‰ã€‚
- **è„‰ç»œåˆ†æ**: æŒ‰ç…§å­¦æœ¯è®ºæ–‡ç»“æ„æå–äº”å¤§æ ¸å¿ƒè„‰ç»œå†…å®¹ã€‚
- **æ‘˜è¦æå–**: æ™ºèƒ½æå–æ‘˜è¦ä¸­çš„å››ä¸ªå…³é”®è¯­æ­¥ï¼ˆèƒŒæ™¯ã€æ–¹æ³•ã€åˆ›æ–°ç‚¹ã€å±€é™ï¼‰ã€‚
- **å›¾è¡¨æ˜ å°„**: å°†å›¾è¡¨æŒ‰æ‰€å±è„‰ç»œåˆ†ç±»å¹¶å»ºç«‹æ˜ å°„å…³ç³»ã€‚
- **å¹¶è¡Œå¤„ç†**: å¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œï¼Œæé«˜å¤„ç†æ•ˆç‡ã€‚
- **å¥åº·æ£€æŸ¥**: å†…ç½®å¥åº·çŠ¶æ€æ£€æŸ¥æ¥å£ï¼Œæ–¹ä¾¿ç›‘æ§ã€‚

## 2. æ ¸å¿ƒæ¥å£: /paper_vis

æ­¤æ¥å£æ˜¯ç³»ç»Ÿçš„ä¸»è¦å…¥å£ï¼Œæ¥æ”¶ä¸€ä¸ªPDFæ–‡ä»¶ï¼Œæ‰§è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ï¼Œå¹¶è¿”å›ç»“æ„åŒ–çš„JSONç»“æœã€‚**<u>ï¼ˆå¯ç›´æ¥è¯»å–å®¢æˆ·ç«¯çš„æœ¬åœ°æ–‡ä»¶ï¼‰</u>**

### 2.1. è¯·æ±‚

- **Endpoint (ç«¯ç‚¹)**
  - `POST http://10.3.35.21:8004/paper_vis`
- **è¯·æ±‚å‚æ•°**
  - è¯·æ±‚ä½“ä¸º `multipart/form-data`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

| å‚æ•°å | ç±»å‹ | æ˜¯å¦å¿…å¡« | æè¿°                    |
| ------ | ---- | -------- | ----------------------- |
| `file` | File | æ˜¯       | ç”¨æˆ·ä¸Šä¼ çš„å•ä¸ªPDFæ–‡ä»¶ã€‚ |

- **å¤‡ç”¨è¯·æ±‚æ–¹å¼**:
  - é™¤äº†ä¸Šä¼ æ–‡ä»¶ï¼Œæ¥å£ä¹Ÿæ”¯æŒé€šè¿‡JSONæŒ‡å®š**æœåŠ¡å™¨æœ¬åœ°**çš„æ–‡ä»¶è·¯å¾„è¿›è¡Œåˆ†æã€‚
  - **Endpoint**: `POST http://10.3.35.21:8004/paper_vis`
  - **Headers**: `Content-Type: application/json`
  - **Body**: `{"pdf_path": "/path/on/server/to/paper.pdf"}`

### 2.2. å“åº” 

- **æˆåŠŸå“åº” **

  - **HTTP çŠ¶æ€ç **: `200 OK`

  - **å“åº”ä½“ (JSON ç¤ºä¾‹)**:

    ```shell
    {
      "success": true,
      "metadata": {
        "title": "HYPOSPACE: EVALUATING LLM CREATIVITY AS SET-VALUED HYPOTHESIS GENERATORS UNDER UNDERDETERMINATION",
        "authors": ["ä½œè€…1", "ä½œè€…2", "ä½œè€…3"]
      },
      "abstract": {
        "background_problem": "èƒŒæ™¯å’Œé—®é¢˜æè¿°",
        "method_approach": "æ–¹æ³•å’Œé€”å¾„",
        "Innovation": "åˆ›æ–°ç‚¹",
        "Limitation/Future Work": "å±€é™å’Œæœªæ¥å·¥ä½œ"
      },
      "lanes": {
        "Context & Related Work": "ç›¸å…³å·¥ä½œå’ŒèƒŒæ™¯å†…å®¹",
        "Methodology & Setup": "æ–¹æ³•è®ºå’Œè®¾ç½®å†…å®¹",
        "Results & Analysis": "ç»“æœå’Œåˆ†æå†…å®¹",
        "Conclusion": "ç»“è®ºå†…å®¹",
        "Innovation Discovery": "å­¦æœ¯åˆ›æ–°æœºä¼šå‘ç°"
      },
      "figure_map": {
        "Context & Related Work": [
          {
            "figure_id": "fig1",
            "caption": "å›¾è¡¨æ ‡é¢˜",
            "content": "ç›¸å…³æ–‡æœ¬å†…å®¹"
          }
        ],
        "Results & Analysis": [
          {
            "figure_id": "fig2",
            "caption": "ç»“æœå›¾è¡¨",
            "content": "ç»“æœç›¸å…³æ–‡æœ¬"
          }
        ]
      },
      "pdf_info": {
        "file_path": "/path/to/paper.pdf",
        "file_size": 1234567,
        "page_count": 10
      },
      "processing_info": {
        "steps_completed": ["pdf_parsing", "abstract_steps", "lane_extraction", "figure_mapping", "final_json_generation"],
        "total_time": 22.54,
        "success": true
      },
      "raw_data": {
        "md_content_length": 50000,
        "content_list_count": 150,
        "figure_dict_count": 8
      }
    
    ```

## 3. è¾…åŠ©æ¥å£

ç”¨äºç›‘æ§æœåŠ¡çš„å¥åº·å’Œè¿è¡ŒçŠ¶æ€ã€‚

### 3.1. GET /health

- **åŠŸèƒ½**: æ£€æŸ¥æœåŠ¡æ˜¯å¦å¥åº·ï¼Œèƒ½å¦å“åº”è¯·æ±‚ã€‚

- **Endpoint**: `GET http://10.3.35.21:8004/health`

- **å“åº”**:

  ```shell
  {
    "status": "healthy",
    "timestamp": "2025-01-27T10:30:00Z"
  }
  ```

### 3.2. GET /status

- **åŠŸèƒ½**: è·å–æœåŠ¡çš„è¯¦ç»†çŠ¶æ€ä¿¡æ¯ï¼Œå¦‚ç‰ˆæœ¬å·ã€è¿è¡Œæ—¶é•¿ã€‚

- **Endpoint**: `GET http://10.3.35.21:8004/status`

- **å“åº”**:

  ```shell
  {
    "status": "running",
    "uptime": 3600,
    "version": "1.0.0"
  }
  ```

## 4. è°ƒç”¨ç¤ºä¾‹

### 4.1. Python è¯·æ±‚

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIæµ‹è¯•å®¢æˆ·ç«¯
æµ‹è¯•æ–‡ä»¶ä¸Šä¼ æ¥å£ /paper_vis
"""

import requests
import json
import time
import os


def test_paper_vis_upload():
    """æµ‹è¯• /paper_vis æ–‡ä»¶ä¸Šä¼ æ¥å£"""
    
    # APIæœåŠ¡å™¨åœ°å€
    base_url = "http://10.3.35.21:8004"
    
    # æµ‹è¯•PDFæ–‡ä»¶è·¯å¾„
    test_pdf_path = "/Users/xiaokong/Desktop/2510.15614v1.pdf"
    
    print("ğŸ§ª æµ‹è¯• /paper_vis æ–‡ä»¶ä¸Šä¼ æ¥å£")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_pdf_path):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_pdf_path}")
        return
    
    print(f"ğŸ“„ ä¸Šä¼ æ–‡ä»¶: {test_pdf_path}")
    print("â³ å¼€å§‹åˆ†æ...")
    
    start_time = time.time()
    
    try:
        # å‡†å¤‡æ–‡ä»¶ä¸Šä¼ 
        with open(test_pdf_path, 'rb') as f:
            files = {
                'file': (os.path.basename(test_pdf_path), f, 'application/pdf')
            }
            
            response = requests.post(
                f"{base_url}/paper_vis",
                files=files,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
        
        end_time = time.time()
        duration = end_time - start_time
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… è®ºæ–‡åˆ†ææˆåŠŸ")
            print(f"â±ï¸ æ€»è€—æ—¶: {duration:.2f}ç§’")
            print(f"ğŸ“Š å¤„ç†ç»“æœ:")
            print(f"   - æˆåŠŸçŠ¶æ€: {result.get('success', False)}")
            print(f"   - å¤„ç†æ—¶é—´: {result.get('total_time', 0):.2f}ç§’")
            
            if result.get('success'):
                print(f"   - è®ºæ–‡æ ‡é¢˜: {result.get('metadata', {}).get('title', 'N/A')}")
                authors = result.get('metadata', {}).get('authors', [])
                print(f"   - ä½œè€…æ•°é‡: {len(authors) if authors else 0}")
                lanes = result.get('lanes', {})
                print(f"   - æ³³é“æ•°é‡: {len(lanes) if lanes else 0}")
                figure_map = result.get('figure_map', {})
                total_figures = sum(len(figures) for figures in figure_map.values()) if figure_map else 0
                print(f"   - å›¾è¡¨æ€»æ•°: {total_figures}")
                
                # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                output_file = "paper_vis_upload_result.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            else:
                print(f"âŒ åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        else:
            print(f"âŒ è®ºæ–‡åˆ†æå¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
            
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰")
    except Exception as e:
        print(f"âŒ è®ºæ–‡åˆ†æå¼‚å¸¸: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ æµ‹è¯•å®Œæˆ")


def test_server_health():
    """æµ‹è¯•æœåŠ¡å™¨å¥åº·çŠ¶æ€"""
    base_url = "http://10.3.35.21:8004"
    
    try:
        # ç›´æ¥æµ‹è¯• /paper_vis æ¥å£çš„OPTIONSè¯·æ±‚
        response = requests.options(f"{base_url}/paper_vis", timeout=10)
        if response.status_code in [200, 405]:  # 405è¡¨ç¤ºæ–¹æ³•ä¸å…è®¸ï¼Œä½†æ¥å£å­˜åœ¨
            print("âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
            return True
        else:
            print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹APIæµ‹è¯•")
    print("=" * 60)
    
    # é¦–å…ˆæµ‹è¯•æœåŠ¡å™¨å¥åº·çŠ¶æ€
    if test_server_health():
        print("\n" + "=" * 60)
        # æµ‹è¯•æ–‡ä»¶ä¸Šä¼ æ¥å£
        test_paper_vis_upload()
    else:
        print("âŒ æœåŠ¡å™¨ä¸å¯ç”¨ï¼Œè¯·å…ˆå¯åŠ¨APIæœåŠ¡å™¨")
        print("   è¿è¡Œå‘½ä»¤: python api_server.py")
```

### 4.2. cURL ç¤ºä¾‹

```shell
# æ–¹å¼ä¸€ï¼šä¸Šä¼ æœ¬åœ°æ–‡ä»¶è¿›è¡Œåˆ†æ
curl -X POST "[http://10.3.35.21:8004/paper_vis](http://10.3.35.21:8004/paper_vis)" \
  -F "file=@/path/to/your/paper.pdf"

# æ–¹å¼äºŒï¼šåˆ†ææœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶
curl -X POST "[http://10.3.35.21:8004/paper_vis](http://10.3.35.21:8004/paper_vis)" \
  -H "Content-Type: application/json" \
  -d '{"pdf_path": "/path/on/server/to/paper.pdf"}'

# æ£€æŸ¥å¥åº·çŠ¶æ€
curl -X GET "[http://10.3.35.21:8004/health](http://10.3.35.21:8004/health)"
```

### 4.3. JavaScript (Fetch API) ç¤ºä¾‹

```javascript
/**
 * è®ºæ–‡åˆ†æAPIå®¢æˆ·ç«¯
 */

// APIåŸºç¡€URL - ä½¿ç”¨ä»£ç†è·¯å¾„é¿å…CORSé—®é¢˜
const API_BASE_URL = process.env.NODE_ENV === 'development' ? '/api' : 'http://10.3.35.21:8004'

/**
 * ä¸Šä¼ PDFæ–‡ä»¶å¹¶è¿›è¡Œåˆ†æ
 * @param {File} pdfFile - PDFæ–‡ä»¶å¯¹è±¡
 * @param {Function} onProgress - è¿›åº¦å›è°ƒå‡½æ•°
 * @returns {Promise<Object>} åˆ†æç»“æœ
 */
export async function analyzePaper(pdfFile, onProgress = null) {
  try {
    console.log('ğŸš€ å¼€å§‹è®ºæ–‡åˆ†æ...')
    console.log('ğŸ“„ æ–‡ä»¶ä¿¡æ¯:', {
      name: pdfFile.name,
      size: pdfFile.size,
      type: pdfFile.type
    })

    // éªŒè¯æ–‡ä»¶ç±»å‹
    if (pdfFile.type !== 'application/pdf') {
      throw new Error('è¯·é€‰æ‹©PDFæ–‡ä»¶')
    }

    // åˆ›å»ºFormData
    const formData = new FormData()
    formData.append('file', pdfFile)

    // æ˜¾ç¤ºè¿›åº¦
    if (onProgress) {
      onProgress(10, 'å‡†å¤‡ä¸Šä¼ æ–‡ä»¶...')
    }

    const startTime = Date.now()

    // å‘é€è¯·æ±‚åˆ° /paper_vis æ¥å£
    const response = await fetch(`${API_BASE_URL}/paper_vis`, {
      method: 'POST',
      body: formData,
      mode: 'cors', // æ˜ç¡®æŒ‡å®šCORSæ¨¡å¼
      headers: {
        // ä¸è®¾ç½®Content-Typeï¼Œè®©æµè§ˆå™¨è‡ªåŠ¨è®¾ç½®multipart/form-data
      },
      // æ³¨æ„ï¼šfetchä¸æ”¯æŒè¿›åº¦å›è°ƒï¼Œè¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿè¿›åº¦
    })

    const endTime = Date.now()
    const duration = (endTime - startTime) / 1000

    if (!response.ok) {
      throw new Error(`æœåŠ¡å™¨é”™è¯¯: ${response.status} ${response.statusText}`)
    }

    const result = await response.json()

    console.log('âœ… è®ºæ–‡åˆ†æå®Œæˆ')
    console.log('â±ï¸ æ€»è€—æ—¶:', duration.toFixed(2), 'ç§’')
    console.log('ğŸ“Š å¤„ç†ç»“æœ:', result)

    // éªŒè¯è¿”å›ç»“æœ
    if (!result.success) {
      throw new Error(result.error || 'åˆ†æå¤±è´¥')
    }

    // æ˜¾ç¤ºæœ€ç»ˆè¿›åº¦
    if (onProgress) {
      onProgress(100, 'åˆ†æå®Œæˆï¼')
    }

    return {
      success: true,
      data: result,
      duration: duration,
      metadata: {
        title: result.metadata?.title || 'æœªçŸ¥æ ‡é¢˜',
        authors: result.metadata?.authors || [],
        totalTime: result.total_time || duration,
        lanesCount: Object.keys(result.lanes || {}).length,
        figuresCount: Object.values(result.figure_map || {}).reduce((total, figures) => total + figures.length, 0)
      }
    }

  } catch (error) {
    console.error('âŒ è®ºæ–‡åˆ†æå¤±è´¥:', error)
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯CORSé”™è¯¯
    let errorMessage = error.message || 'æœªçŸ¥é”™è¯¯'
    if (error.message.includes('CORS') || error.message.includes('Failed to fetch')) {
      errorMessage = 'è·¨åŸŸè¯·æ±‚è¢«é˜»æ­¢ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡å™¨CORSé…ç½®æˆ–ä½¿ç”¨ä»£ç†'
    }
    
    // æ˜¾ç¤ºé”™è¯¯è¿›åº¦
    if (onProgress) {
      onProgress(0, `åˆ†æå¤±è´¥: ${errorMessage}`)
    }

    return {
      success: false,
      error: errorMessage,
      data: null
    }
  }
}

/**
 * æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€
 * @returns {Promise<boolean>} æœåŠ¡å™¨æ˜¯å¦å¯ç”¨
 */
export async function checkServerHealth() {
  try {
    const response = await fetch(`${API_BASE_URL}/paper_vis`, {
      method: 'OPTIONS',
      timeout: 10000
    })
    
    // 200æˆ–405éƒ½è¡¨ç¤ºæ¥å£å­˜åœ¨
    return response.status === 200 || response.status === 405
  } catch (error) {
    console.warn('æœåŠ¡å™¨å¥åº·æ£€æŸ¥å¤±è´¥:', error)
    return false
  }
}

/**
 * æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°ï¼ˆå› ä¸ºfetchä¸æ”¯æŒè¿›åº¦å›è°ƒï¼‰
 * @param {Function} onProgress - è¿›åº¦å›è°ƒå‡½æ•°
 * @param {number} duration - é¢„è®¡æ€»æ—¶é•¿ï¼ˆç§’ï¼‰
 */
export function simulateProgress(onProgress) {
  let progress = 0
  const interval = setInterval(() => {
    progress += Math.random() * 10
    if (progress >= 90) {
      progress = 90
      clearInterval(interval)
    }
    
    const statuses = [
      'æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...',
      'PDFè§£æä¸­...',
      'å†…å®¹æŠ½å–ä¸­...',
      'è¯­ä¹‰åˆ†æä¸­...',
      'ç”Ÿæˆç»“æœä¸­...'
    ]
    
    const statusIndex = Math.floor((progress / 100) * statuses.length)
    const status = statuses[Math.min(statusIndex, statuses.length - 1)]
    
    onProgress(Math.floor(progress), status)
  }, 1000)

  return interval
}

```

## 5. æ³¨æ„äº‹é¡¹

1. **æ–‡ä»¶è·¯å¾„**: ä½¿ç”¨JSONè¯·æ±‚æ—¶ï¼Œè¯·ç¡®ä¿ `pdf_path` æ˜¯æœåŠ¡å™¨å¯è®¿é—®çš„ç»å¯¹è·¯å¾„ã€‚
2. **å¤„ç†æ—¶é—´**: å¤§å‹æˆ–å¤æ‚çš„PDFè®ºæ–‡å¯èƒ½éœ€è¦è¾ƒé•¿çš„å¤„ç†æ—¶é—´ï¼Œå®¢æˆ·ç«¯åº”è®¾ç½®è¶³å¤Ÿé•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆå»ºè®®2åˆ†é’Ÿä»¥ä¸Šï¼‰ã€‚
3. **æ–‡ä»¶æ ¼å¼**: ç›®å‰ä»…æ”¯æŒæ ‡å‡†çš„PDFæ ¼å¼æ–‡ä»¶ã€‚

## è¿ç»´ç¬”è®°

- **æ¥å£ç«¯å£**: `8004`

- **é…ç½®é¡¹åœ°å€**: `/etc/systemd/system/paper-vis-api.service`

- **ä»£ç ä½ç½®**: `/data/kongyb/paper_vis/paper_vis/api_server.py`

- **æ¥å£æºä»£ç **:

  ```python
  #!/usr/bin/env python3
  # -*- coding: utf-8 -*-
  """
  FastAPI æœåŠ¡å™¨ - å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææ¥å£
  åŸºäº MainScheduler çš„å®Œæ•´è®ºæ–‡å¤„ç†ç³»ç»Ÿ
  
  å”¯ä¸€æ¥å£ï¼š
  POST /paper_vis
  - è¾“å…¥ï¼šä¸Šä¼ PDFæ–‡ä»¶
  - è¾“å‡ºï¼šMainSchedulerçš„å®Œæ•´JSONç»“æœ
  """
  from fastapi.middleware.cors import CORSMiddleware
  from fastapi import FastAPI, HTTPException, UploadFile, File
  import uvicorn
  
  # å¯¼å…¥ä¸»è°ƒåº¦å™¨
  from MainScheduler import MainScheduler
  
  
  # åˆ›å»ºFastAPIåº”ç”¨
  app = FastAPI(
      title="å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPI",
      description="åŸºäºAIçš„å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æç³»ç»Ÿ",
      version="1.0.0"
  )
  
  origins = ["*"]
  
  # å°† CORS ä¸­é—´ä»¶æ·»åŠ åˆ°ä½ çš„åº”ç”¨ä¸­
  app.add_middleware(
      CORSMiddleware,
      allow_origins=origins,  # ä½¿ç”¨æ–°çš„ origins åˆ—è¡¨
      allow_credentials=True,
      allow_methods=["*"],
      allow_headers=["*"],
  )
  
  @app.post("/paper_vis")
  async def paper_vis(file: UploadFile = File(...)):
      """
      åˆ†æPDFè®ºæ–‡ - å”¯ä¸€æ¥å£
      
      è¾“å…¥ï¼š
      - file: ä¸Šä¼ çš„PDFæ–‡ä»¶
      
      è¾“å‡ºï¼š
      - MainSchedulerçš„å®Œæ•´JSONç»“æœ
      """
      try:
          print(f"ğŸš€ å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {file.filename}")
          
          # æ£€æŸ¥æ–‡ä»¶ç±»å‹
          if not file.filename.lower().endswith('.pdf'):
              raise HTTPException(
                  status_code=400, 
                  detail="åªæ”¯æŒPDFæ–‡ä»¶æ ¼å¼"
              )
          
          # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹
          file_content = await file.read()
          
          # åˆ›å»ºä¸»è°ƒåº¦å™¨å®ä¾‹
          scheduler = MainScheduler()
          
          # æ‰§è¡Œå®Œæ•´çš„è®ºæ–‡åˆ†ææµç¨‹ï¼ˆç›´æ¥ä½¿ç”¨æ–‡ä»¶å†…å®¹ï¼Œä¸ä¿å­˜åˆ°æœåŠ¡å™¨ï¼‰
          result = scheduler.process_uploaded_pdf(file_content, file.filename)
          
          return result
              
      except Exception as e:
          print(f"âŒ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {e}")
          raise HTTPException(
              status_code=500,
              detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"
          )
  
  
  if __name__ == "__main__":
      print("ğŸš€ å¯åŠ¨å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPIæœåŠ¡å™¨...")
      print("ğŸ“¡ æœåŠ¡åœ°å€: http://10.3.35.21:8004")
      print("ğŸ“Š å”¯ä¸€æ¥å£: POST /paper_vis")
      print("=" * 60)
      
      # å¯åŠ¨æœåŠ¡å™¨
      uvicorn.run(
          "api_server:app",
          host="0.0.0.0",
          port=8004,
          reload=True,
          log_level="info"
      )
  ```

  # äº”ã€ å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææœåŠ¡å¹³å° 

  ## 1. æ¦‚è§ˆ

  - **å¹³å°åç§°**: å­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†ææœåŠ¡å¹³å°
  - **å¹³å°çŠ¶æ€**: `[ç¨³å®š]`
  - **å¹³å°æè¿°**: æœ¬å¹³å°æ˜¯â€œå­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPIâ€çš„å¯è§†åŒ–å‰ç«¯ç•Œé¢ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ä¸ªä¾¿æ·çš„å›¾å½¢åŒ–æ“ä½œçª—å£ï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ PDFæ–‡ä»¶ï¼Œå¹¶ç›´è§‚åœ°æŸ¥çœ‹åˆ†æç»“æœã€‚

  ![50a3614bcb6612ad37ba3bce27bfd143](/Users/xiaokong/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_e0erez0j9yre22_7560/temp/RWTemp/2025-10/50a3614bcb6612ad37ba3bce27bfd143.png)

  ![7f5bea41e11b370867ebba38be801295](/Users/xiaokong/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_e0erez0j9yre22_7560/temp/RWTemp/2025-10/7f5bea41e11b370867ebba38be801295.png)

  ![338bb8e07c311fcc83a19cebbf1fbd44](/Users/xiaokong/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_e0erez0j9yre22_7560/temp/RWTemp/2025-10/338bb8e07c311fcc83a19cebbf1fbd44.png)

  ## 2. è®¿é—®åœ°å€

  - **å¹³å°è®¿é—®é“¾æ¥**:
    - `http://10.3.35.21:8080/upload`

  ## 3. æ³¨æ„äº‹é¡¹

  1. **æµè§ˆå™¨å…¼å®¹æ€§**: å»ºè®®ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬çš„ Chrome, Firefox, æˆ– Edge æµè§ˆå™¨ä»¥è·å¾—æœ€ä½³ä½“éªŒã€‚
  2. **æ–‡ä»¶ä¸Šä¼ **: ç”¨æˆ·é€šè¿‡æ­¤å¹³å°ä¸Šä¼ çš„PDFæ–‡ä»¶ï¼Œå°†ç”±åç«¯â€œå­¦æœ¯è®ºæ–‡æ™ºèƒ½åˆ†æAPIâ€ (`http://10.3.35.21:8004`) è¿›è¡Œå¤„ç†ã€‚
  3. **ç½‘ç»œç¯å¢ƒ**: è¯·ç¡®ä¿å®¢æˆ·ç«¯èƒ½å¤Ÿè®¿é—®æœåŠ¡å™¨ `10.3.35.21` çš„ `8080` ç«¯å£ã€‚

  ## è¿ç»´è®°å½•

  - **æœåŠ¡ç«¯å£**: `8080`

  - **WebæœåŠ¡å™¨é…ç½®**: `/etc/nginx/sites-enabled/paper-vis-frontend`

  - **é¡¹ç›®ä»£ç ä½ç½®**: `/data/kongyb/paper_vis/frontend/`

    

    